{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da7491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154d2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Numerical issues were encountered \")\n",
    "warnings.filterwarnings(\"ignore\", message=\"lbfgs failed to converge \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cee3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3fae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV\n",
    "# Source: http://www.openslr.org/83/\n",
    "df = pd.read_csv('line_index_all.csv', names=['lineID', 'filename', 'transcript'])\n",
    "\n",
    "# Create label column\n",
    "df['filename'] = [filename.strip() for filename in df.filename] # Remove whitespace\n",
    "df['speaker'] = [string[:9] for string in df.filename]\n",
    "df['source'] = [string[:3] for string in df.filename] # three-letter code indicating speaker dialect+sex (& directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff13485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker lists (for shuffling later)\n",
    "\n",
    "df_wef = df[df.source == 'wef']  # Welsh English Female\n",
    "df_wem = df[df.source == 'wem']  # Welsh English Male\n",
    "df_mif = df[df.source == 'mif']  # Midlands English Female\n",
    "df_mim = df[df.source == 'mim']  # Midlands English Male\n",
    "df_nof = df[df.source == 'nof']  # Northern English Female\n",
    "df_nom = df[df.source == 'nom']  # Northern English Male\n",
    "df_scf = df[df.source == 'scf']  # Scottish English Female\n",
    "df_scm = df[df.source == 'scm']  # Scottish English Male\n",
    "df_sof = df[df.source == 'sof']  # Southern English Female\n",
    "df_som = df[df.source == 'som']  # Southern English Male\n",
    "\n",
    "speaker_list_we = list(df_wef.speaker.unique()) + list(df_wem.speaker.unique())\n",
    "speaker_list_mi = list(df_mif.speaker.unique()) + list(df_mim.speaker.unique())\n",
    "speaker_list_no = list(df_nof.speaker.unique()) + list(df_nom.speaker.unique())\n",
    "speaker_list_sc = list(df_scf.speaker.unique()) + list(df_scm.speaker.unique())\n",
    "speaker_list_so = list(df_sof.speaker.unique()) + list(df_som.speaker.unique())\n",
    "\n",
    "# Class list (in alphabetical order)\n",
    "labels = ['Midlands', 'Northern', 'Scottish', 'Southern', 'Welsh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba16b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature lists\n",
    "\n",
    "# MFCCs only\n",
    "colnames_mfcc16 = []  # n=16 MFCCs\n",
    "\n",
    "for n in range(16):\n",
    "    num = n+1\n",
    "    if num < 10:\n",
    "        num = '0' + str(num)\n",
    "    else:\n",
    "        num = str(num)\n",
    "    name = 'mfcc_' + num\n",
    "    colnames_mfcc16.append(name)\n",
    "    \n",
    "# MFCC-deltas, MFCC-delta-deltas\n",
    "# 26-Oct: Do not use, does not add much predictive value\n",
    "colnames_mfcc16_del = [(name + '_del') for name in colnames_mfcc16]\n",
    "colnames_mfcc16_del2 = [(name + '_del2') for name in colnames_mfcc16]\n",
    "\n",
    "# Formants only\n",
    "# Note 'mif' choice is arbitrary, same column names for every df_formants_*\n",
    "df_formants_mim = pd.read_pickle(\"df_formants_mim.pkl\")\n",
    "colnames_formants = list(df_formants_mim.columns[2:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485a33d",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7059a786",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_mfcc16s_and_formants.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8048/2950521054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df_mfcc16s_and_formants.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\metis\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \"\"\"\n\u001b[0;32m    195\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\metis\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_mfcc16s_and_formants.pkl'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_full = pd.read_pickle(\"df_mfcc16s_and_formants.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "# 27-Oct: Remove all Midlands speakers due to small sample size\n",
    "df_full = df_full[df_full['label'] != 'mi']\n",
    "labels = ['Northern', 'Scottish', 'Southern', 'Welsh']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d68461",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive formant-related features\n",
    "\n",
    "# 0. Normalize with respect to F0\n",
    "for name in colnames_formants[3:]:\n",
    "    df_full[name] = df_full[name] / df_full['meanF0Hz']\n",
    "df_full['meanF0Hz'] = 1.0\n",
    "\n",
    "# 1. F2/F1 (vowel pronunciation)\n",
    "df_full['f2/f1_mean']   = df_full['f2_mean'] / df_full['f1_mean']\n",
    "df_full['f2/f1_median'] = df_full['f2_median'] / df_full['f1_median']\n",
    "\n",
    "# 2. F3/F2 (rhoticity; 'r' sounds)\n",
    "df_full['f3/f2_mean']   = df_full['f3_mean'] / df_full['f2_mean']\n",
    "df_full['f3/f2_median'] = df_full['f3_median'] / df_full['f2_median']\n",
    "\n",
    "# 3. F3/F1 (not sure; for completeness)\n",
    "df_full['f3/f1_mean']   = df_full['f3_mean'] / df_full['f1_mean']\n",
    "df_full['f3/f1_median'] = df_full['f3_median'] / df_full['f1_median']\n",
    "\n",
    "formant_features = list(colnames_formants[3:]) + \\\n",
    "                        ['f2/f1_mean', 'f2/f1_median', 'f3/f2_mean', 'f3/f2_median',\n",
    "                         'f3/f1_mean', 'f3/f1_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92883506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[formant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c51c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec17734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary labels for OVR comparisons\n",
    "\n",
    "df_full['is_scottish'] = np.where(df_full['label'] == 'sc', 1, 0)\n",
    "df_full['is_welsh']    = np.where(df_full['label'] == 'we', 1, 0)\n",
    "df_full['is_northern'] = np.where(df_full['label'] == 'no', 1, 0)\n",
    "df_full['is_southern'] = np.where(df_full['label'] == 'so', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b8713",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9d84e",
   "metadata": {},
   "source": [
    " 1. **Dataset must be split according to speaker ID**. Randomly splitting entries will cause most speakers to be represented in both the train and test datasets. Selecting MFCCs as features would perform extremely well in this context because MFCCs are highly correlated between utterances of any given speaker, but amounts to voice matching, and out-of-sample data/speakers would be poorly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train:test split (df_full -> df_train, df_test)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "S = speaker_list_we\n",
    "random.shuffle(S)\n",
    "index = int(len(S)*0.8)  # for 80:20 split\n",
    "speakers_we_test = S[index:]\n",
    "speakers_we_train = S[:index]\n",
    "df_train_we = df_full[(df_full.speaker.isin(speakers_we_train) & (df_full.label == 'we'))]\n",
    "df_test_we = df_full[(df_full.speaker.isin(speakers_we_test) & (df_full.label == 'we'))]\n",
    "\n",
    "S = speaker_list_no\n",
    "random.shuffle(S)\n",
    "index = int(len(S)*0.8)  # for 80:20 split\n",
    "speakers_no_test = S[index:]\n",
    "speakers_no_train = S[:index]\n",
    "df_train_no = df_full[(df_full.speaker.isin(speakers_no_train) & (df_full.label == 'no'))]\n",
    "df_test_no = df_full[(df_full.speaker.isin(speakers_no_test) & (df_full.label == 'no'))]\n",
    "\n",
    "S = speaker_list_so\n",
    "random.shuffle(S)\n",
    "index = int(len(S)*0.8)  # for 80:20 split\n",
    "speakers_so_test = S[index:]\n",
    "speakers_so_train = S[:index]\n",
    "df_train_so = df_full[(df_full.speaker.isin(speakers_so_train) & (df_full.label == 'so'))]\n",
    "df_test_so = df_full[(df_full.speaker.isin(speakers_so_test) & (df_full.label == 'so'))]\n",
    "\n",
    "S = speaker_list_sc\n",
    "random.shuffle(S)\n",
    "index = int(len(S)*0.8)  # for 80:20 split\n",
    "speakers_sc_test = S[index:]\n",
    "speakers_sc_train = S[:index]\n",
    "df_train_sc = df_full[(df_full.speaker.isin(speakers_sc_train) & (df_full.label == 'sc'))]\n",
    "df_test_sc = df_full[(df_full.speaker.isin(speakers_sc_test) & (df_full.label == 'sc'))]\n",
    "\n",
    "df_train = pd.concat([df_train_we, df_train_no, df_train_so, df_train_sc], axis=0)\n",
    "df_test =  pd.concat([df_test_we, df_test_no, df_test_so, df_test_sc], axis=0)\n",
    "\n",
    "print(f'Entries (speakers) in Train dataset:  {df_train.shape[0]} ({len(list(df_train.speaker.unique()))})')\n",
    "print(f'Entries (speakers) in Test dataset:   {df_test.shape[0]} ({len(list(df_test.speaker.unique()))})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06cad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train:val split (df_train -> df_train2, df_val)\n",
    "\n",
    "list_train = []\n",
    "list_val = []\n",
    "\n",
    "for accent in ['we', 'no', 'so', 'sc']:\n",
    "    S = list(df_train[df_train['label'] == accent].speaker.unique())\n",
    "    random.shuffle(S)\n",
    "    index = int(len(S)*0.75)  # for 75:25 split (train:val)\n",
    "    speakers_val = S[index:]\n",
    "    speakers_train = S[:index]\n",
    "    \n",
    "    df_train_ = df_train[(df_train.speaker.isin(speakers_train)) & (df_train.label == accent)]\n",
    "    list_train.append(df_train_)\n",
    "    df_val_ = df_train[(df_train.speaker.isin(speakers_val)) & (df_train.label == accent)]\n",
    "    list_val.append(df_val_)\n",
    "    \n",
    "df_train2 = pd.concat(list_train, axis=0)\n",
    "df_val = pd.concat(list_val, axis=0)\n",
    "\n",
    "print(f'Entries (speakers) in Train dataset:  {df_train2.shape[0]} ({len(list(df_train2.speaker.unique()))})')\n",
    "print(f'Entries (speakers) in Val dataset:   {df_val.shape[0]} ({len(list(df_val.speaker.unique()))})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c58e48",
   "metadata": {},
   "source": [
    "2. MFCC-deltas & MFCC-delta2s are **not** used as features in any models below, since introducing them was found to introduce complexity with negligible performance gains, even reducing F1 score for certain classes. (See DataPrep notebook for specific examples.)  However, they can be tested in the current notebook by adding the feature lists `colnames_mfcc16_del` and/or `colnames_mfcc16_del2` to `colnames_mfcc16` in X_train/val/test below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d416c",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4d21e",
   "metadata": {},
   "source": [
    "**KNN: k=5**  \n",
    "Cross-validated F1 score seems to take a maximum where k = 3, in all four classes. However, k=4 and k=5 seem reasonably close to the maximum, and could help to reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df_train[colnames_mfcc16+formant_features]\n",
    "y_sc = df_train['is_scottish']\n",
    "y_we = df_train['is_welsh']\n",
    "y_no = df_train['is_northern']\n",
    "y_so = df_train['is_southern']\n",
    "\n",
    "k_range = list(range(1,31))\n",
    "k_scores_sc = []\n",
    "k_scores_so = []\n",
    "k_scores_no = []\n",
    "k_scores_we = []\n",
    "k_scores_all = []\n",
    "\n",
    "for k in tqdm(k_range):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y_sc, cv=10, scoring='f1')  # y_sc = Scottish v. rest, etc.\n",
    "    k_scores_sc.append(scores.mean())\n",
    "    scores = cross_val_score(knn, X, y_so, cv=10, scoring='f1')  \n",
    "    k_scores_so.append(scores.mean())\n",
    "    scores = cross_val_score(knn, X, y_no, cv=10, scoring='f1')  \n",
    "    k_scores_no.append(scores.mean())\n",
    "    scores = cross_val_score(knn, X, y_we, cv=10, scoring='f1') \n",
    "    k_scores_we.append(scores.mean())\n",
    "    score = (k_scores_sc[-1] + k_scores_so[-1] +\n",
    "             k_scores_no[-1] + k_scores_we[-1]) / 4\n",
    "    k_scores_all.append(score)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(k_scores_sc, color = 'green', label = 'Scottish')\n",
    "ax.plot(k_scores_we, color = 'blue', label = 'Welsh')\n",
    "ax.plot(k_scores_no, color = 'yellow', label = 'Northern')\n",
    "ax.plot(k_scores_so, color = 'red', label = 'Southern')\n",
    "ax.plot(k_scores_all, color = 'black', label = '4-CLASS MEAN')\n",
    "ax.legend(loc = 'upper right')\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checking CV scores of different models and parameters\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=) # enter k here\n",
    "# model = LogisticRegression(solver='liblinear')   # optional: class_weight='balanced'\n",
    "# model = DecisionTreeClassifier(max_depth=)\n",
    "# model = RandomForestClassifier(n_estimators=) # optional: class_weight='balanced'\n",
    "\n",
    "X = df_train[colnames_mfcc16]\n",
    "y_sc = df_train['is_scottish']\n",
    "y_we = df_train['is_welsh']\n",
    "y_no = df_train['is_northern']\n",
    "y_so = df_train['is_southern']\n",
    "\n",
    "scores_sc = cross_val_score(knn, X, y_sc, cv=10, scoring='f1')\n",
    "scores_we = cross_val_score(knn, X, y_we, cv=10, scoring='f1')\n",
    "scores_no = cross_val_score(knn, X, y_no, cv=10, scoring='f1')\n",
    "scores_so = cross_val_score(knn, X, y_so, cv=10, scoring='f1')\n",
    "\n",
    "print(f'CV scores for Scottish: Mean={np.mean(scores_sc)}, \\n List: {scores_sc}')\n",
    "print(f'CV scores for Welsh:    Mean={np.mean(scores_we)}, \\n List: {scores_we}')\n",
    "print(f'CV scores for Northern: Mean={np.mean(scores_no)}, \\n List: {scores_no}')\n",
    "print(f'CV scores for Southern: Mean={np.mean(scores_so)}, \\n List: {scores_so}')\n",
    "\n",
    "mean_CV = np.mean([np.mean(scores_sc), np.mean(scores_we),  \n",
    "                   np.mean(scores_so), np.mean(scores_no)])\n",
    "\n",
    "print(f'\\n Mean CV across all four classes: {mean_CV}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8b08a",
   "metadata": {},
   "source": [
    "**Decision tree: max_depth = 3**  \n",
    "Shallower decision trees seem to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_range = list(range(1,31))\n",
    "max_depth_sc = []\n",
    "max_depth_so = []\n",
    "max_depth_no = []\n",
    "max_depth_we = []\n",
    "max_depth_mean = []\n",
    "\n",
    "for maxdepth in tqdm(depth_range):\n",
    "    dtc = DecisionTreeClassifier(max_depth=maxdepth)\n",
    "    scores = cross_val_score(dtc, X, y_sc, cv=10, scoring='f1')  # y_sc = Scottish v. rest, etc.\n",
    "    max_depth_sc.append(scores.mean())\n",
    "    scores = cross_val_score(dtc, X, y_so, cv=10, scoring='f1')  \n",
    "    max_depth_so.append(scores.mean())\n",
    "    scores = cross_val_score(dtc, X, y_no, cv=10, scoring='f1')  \n",
    "    max_depth_no.append(scores.mean())\n",
    "    scores = cross_val_score(dtc, X, y_we, cv=10, scoring='f1') \n",
    "    max_depth_we.append(scores.mean())\n",
    "    score = (max_depth_sc[-1] + max_depth_so[-1] +\n",
    "             max_depth_no[-1] + max_depth_we[-1]) / 4\n",
    "    max_depth_mean.append(score)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(max_depth_sc, color = 'green', label = 'Scottish')\n",
    "ax.plot(max_depth_we, color = 'blue', label = 'Welsh')\n",
    "ax.plot(max_depth_no, color = 'yellow', label = 'Northern')\n",
    "ax.plot(max_depth_so, color = 'red', label = 'Southern')\n",
    "ax.plot(max_depth_mean, color = 'black', label = '4-CLASS MEAN')\n",
    "ax.legend(loc = 'upper right')\n",
    "plt.xlabel('Max_depth - DecisionTreeClassifier')\n",
    "plt.ylabel('Cross-Validated F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8276ff",
   "metadata": {},
   "source": [
    "**Random forest: n_estimators = 100**  \n",
    "No appreciable change in F1 score over the range examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933281a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_range = list(range(5,205,5))\n",
    "n_est_sc = []\n",
    "n_est_so = []\n",
    "n_est_no = []\n",
    "n_est_we = []\n",
    "n_est_mean = []\n",
    "\n",
    "for n_est in tqdm(est_range):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est)\n",
    "    scores = cross_val_score(rf, X, y_sc, cv=10, scoring='f1')  # y_sc = Scottish v. rest, etc.\n",
    "    n_est_sc.append(scores.mean())\n",
    "    scores = cross_val_score(rf, X, y_so, cv=10, scoring='f1')  \n",
    "    n_est_so.append(scores.mean())\n",
    "    scores = cross_val_score(rf, X, y_no, cv=10, scoring='f1')  \n",
    "    n_est_no.append(scores.mean())\n",
    "    scores = cross_val_score(rf, X, y_we, cv=10, scoring='f1') \n",
    "    n_est_we.append(scores.mean())\n",
    "    score = (n_est_sc[-1] + n_est_so[-1] +\n",
    "             n_est_no[-1] + n_est_we[-1]) / 4\n",
    "    n_est_mean.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24019088",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# multiply x-axis value by 5 for n_estimators: e.g. '20' * 5 = 100\n",
    "\n",
    "ax.plot(n_est_sc, color = 'green', label = 'Scottish')\n",
    "ax.plot(n_est_we, color = 'blue', label = 'Welsh')\n",
    "ax.plot(n_est_no, color = 'yellow', label = 'Northern')\n",
    "ax.plot(n_est_so, color = 'red', label = 'Southern')\n",
    "ax.plot(n_est_mean, color = 'black', label = '4-CLASS MEAN')\n",
    "ax.legend(loc = 'upper right')\n",
    "plt.xlabel('Number of estimators (RF)')\n",
    "plt.ylabel('Cross-Validated F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01882c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d20378",
   "metadata": {},
   "source": [
    "### Current models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c57dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[colnames_mfcc16+formant_features]\n",
    "y_train = df_train['label']\n",
    "X_test = df_test[colnames_mfcc16+formant_features]\n",
    "y_test = df_test['label']\n",
    "\n",
    "def get_confusion_matrix(model):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', \\\n",
    "            fmt='g', xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "# model = LogisticRegression(solver='liblinear')   # optional: class_weight='balanced'\n",
    "# model = DecisionTreeClassifier(max_depth=3)\n",
    "# model = RandomForestClassifier(n_estimators=) # optional: class_weight='balanced'\n",
    "\n",
    "get_confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91ae85",
   "metadata": {},
   "source": [
    "### To Do:\n",
    "1. ~~Tune DecisionTreeClassifier (CV)~~\n",
    "2. ~~Tune RandomForestClassifier (CV)~~\n",
    "3. Ensembling?\n",
    "4. XGBoost (GradientBoostedTrees) + tuning\n",
    "5. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb4b5f",
   "metadata": {},
   "source": [
    "**XGBoost (gradient boosting trees):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51838fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train2[colnames_mfcc16+\n",
    "                  formant_features]  # Compare with colnames_mfcc16_del, colnames_mfcc16_del2\n",
    "y_train = df_train2['label']\n",
    "X_val = df_val[colnames_mfcc16+\n",
    "                formant_features]    # Compare with colnames_mfcc16_del, colnames_mfcc16_del2\n",
    "y_val = df_val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10578b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ],\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(clf,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc72a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier(n_estimators=30000,\n",
    "                       max_depth=4,\n",
    "                       objective='multi:softprob',\n",
    "                       learning_rate=.05,\n",
    "                       subsample=.8,\n",
    "                       min_child_weight=3,\n",
    "                       colsample_bytree=.8)\n",
    "\n",
    "eval_set=[(X_train,y_train),(X_val,y_val)]\n",
    "\n",
    "fit_model = gbm.fit(X_train, y_train,\n",
    "                   eval_set=eval_set,\n",
    "                   eval_metric='merror',\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose=False)\n",
    "\n",
    "f1_score(y_test, gbm.predict(X_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b5bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbdf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5e806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84ee10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908a0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0099bf62",
   "metadata": {},
   "source": [
    "### Reference: Multi-class ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "  #creating a set of all the unique classes using the actual class list\n",
    "  unique_class = set(actual_class)\n",
    "  roc_auc_dict = {}\n",
    "  for per_class in unique_class:\n",
    "    #creating a list of all the classes except the current class \n",
    "    other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "    #marking the current class as 1 and all other classes as 0\n",
    "    new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "    new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "    #using the sklearn metrics method to calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "    roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "  return roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# X_s, y_s = shuffle(X, y)\n",
    "# cross_val_score(knn, X_s, y_s, cv=3, scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7eef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "print(roc_auc_score_multiclass(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58864a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ce0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16e45687",
   "metadata": {},
   "source": [
    "### Reference: Audio processing of a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate path\n",
    "path = 'midlands_english_female/' + 'mif_02484_00047480027' + '.wav'\n",
    "\n",
    "# 2. Import audio file\n",
    "y, sr = librosa.load(path, sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c62150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate MFCCs\n",
    "# 3.1 Import wav file\n",
    "\n",
    "path = 'midlands_english_female/mif_02484_00047480027.wav'\n",
    "y, sr = librosa.load(path, sr=22050)  # 'data are stored at 48 kHz' in publication\n",
    "ipd.Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Plot speech waveform\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(y, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0262d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Calcuate MFCCs\n",
    "\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "#mfccs = preprocessing.scale(mfccs, axis=1)  # for use in MVP fig only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Plot spectrogram\n",
    "\n",
    "D = librosa.stft(y)  # STFT of y\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=ax)\n",
    "ax.set(title='Spectrogram')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "ipd.Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Plot MFCC spectra\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(mfccs, x_axis='time', y_axis='linear', ax=ax)\n",
    "fig.colorbar(img, ax=ax)\n",
    "ax.set(title='MFCCs (unscaled)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
