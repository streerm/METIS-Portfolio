{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71534d26",
   "metadata": {},
   "source": [
    "## Module #5 Minimum Viable Product\n",
    "\n",
    "### Mark Streer (DS/ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aaf317",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "Globally, scientific literature is disseminated in English, yet the language is spoken by fewer than 20% of the world's population, and only 5% speak it natively. Researchers working in non-Anglophone countries normally enlist help from translators and/or editors in order to publish in their second language; however, language professionals are inconsistent in their diction and writing style, leaving their customers to question the value of their services. Could biomedical corpora be used as reference repositories of expected genre-specific language for native English (L1) translators to consult when translating, and for ESL (L2) authors to check/edit their work? In this project, I examine a collection of technical translations from Japanese to English by the same translator (myself), aiming to model topics in the corpus, analyze the most salient words for each topic, and see if they can be traced back to consistent keywords in the Japanese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbe78b",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "The dataset analyzed consists of the English texts of my technical translations from Japanese to English in 2020-2021. These documents are generally original research articles (RAs; or their abstract) in IMRAD format (n=117). The Japanese authors range from graduate students writing their first scientific paper, to professors and physicians writing their 20th; the sophistication of the lexis and syntax in their source texts is similarly diverse. Likewise, scientific corpora are normally drawn from a wide variety of sources and authors. Despite this variation, the rules applied to distill technical Japanese from diverse authors and domains should be relatively **consistent** within any given translator, corresponding to their personal translation style.\n",
    "\n",
    "Given the length of each document, latent Dirichlet allocation is applied to sort them into topics. Topics are expected to roughly correspond to the domains of clinical research covered by the corpus: neuroscience, nursing, gerontology, pharmaceuticals, and civil engineering (if memory serves) should be among the most well represented.\n",
    "\n",
    "Preprocessing was applied to remove punctuation and small words (<4 characters); the results were lemmatized using WordNetLemmatizer. Optionally, a list of the 1000 most-common English words was added to the stopwords list for vectorization. TF-IDF vectorization proved tricky to generate good results, so simple count vectors are applied for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed65924",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3d4191",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'master_list_20211108.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aa67db572b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'master_list_20211108.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmaster_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmaster_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'master_list_20211108.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('master_list_20211108.pkl')\n",
    "master_list = list(df.iloc[:,0])\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_vectorizer = CountVectorizer(stop_words='english', max_df=0.3)\n",
    "doc_word_tf = tf_vectorizer.fit_transform(master_list)\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# for TF DTM\n",
    "lda_tf = LatentDirichletAllocation(n_components=30, random_state=0)\n",
    "lda_tf.fit(doc_word_tf)\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(lda_tf, doc_word_tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f80b8",
   "metadata": {},
   "source": [
    "#### Classification performance\n",
    "\n",
    "* Random forest models resulted in the best performance across the four model types tested, followed by K nearest neighbors (k=10), decision tree, and logistic regression. \n",
    "* Strong bias is apparent towards the majority class (Southern) in the logistic regression and decision tree models. Southern-versus-all classification consistently earns the highest f1-score in all models (OVA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3c873",
   "metadata": {},
   "source": [
    "![](mvp_fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e19b1",
   "metadata": {},
   "source": [
    "![](mvp_fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11c236",
   "metadata": {},
   "source": [
    "Further work will:\n",
    "1. Re-run analysis using 16 MFCCs - the conventional size in speech processing algorithms - instead of the Librosa default of 20.\n",
    "2. Split train/test datasets by user to ensure the model is not merely determining speaker similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f12e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
