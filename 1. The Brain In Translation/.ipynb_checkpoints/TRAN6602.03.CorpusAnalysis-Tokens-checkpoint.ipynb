{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d386e32e",
   "metadata": {},
   "source": [
    "#### (4月12日) Corpus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99017208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle\n",
    "corpus_new = pd.read_pickle('savefiles/corpusfull_20220410.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8e24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get custom functions\n",
    "from functions import collapse, preprocess_gen, initialize_results_df, unique, find_tokens_unique_to_one_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37e6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts each doc from list of paras to one long string\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = collapse(corpus_new.loc[i, \"Text\"])\n",
    "\n",
    "# Preprocess each doc before Spacy modeling\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = preprocess_gen(corpus_new.loc[i, \"Text\"])\n",
    "    \n",
    "# For practicing on single texts\n",
    "# text = corpus_new.loc[0, \"Text\"]\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeefcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row indices of docs in respective corpora\n",
    "jpen_i = [0,  1,  5, 10, 11, 12, 13, 14, 17, 19]\n",
    "enen_i = [2,  3,  4,  6,  7,  8,  9, 15, 16, 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92036ceb",
   "metadata": {},
   "source": [
    "#### Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fabb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f0b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tok(doc):\n",
    "    \n",
    "    # Collect lemmas not tagged by spaCy as 1. punctuation, 2. digits, 3. URLs, or 4. stop words\n",
    "    tokens = [tok.lemma_ for tok in doc if not (tok.is_punct | tok.is_digit | tok.like_url | tok.is_stop)]\n",
    "    \n",
    "    # Remove any tokens containing mid-string digits (e.g. \"P5-a\") or punc ('t(are')\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\d\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\(\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\)\", tok)]\n",
    "    \n",
    "    # (4.13) Break apart hyphen- or slash-separated compounds\n",
    "    seps = ['-', '–', '―',\n",
    "            ';', ':',\n",
    "            '\\]', '\\[', \n",
    "            '’', '”', \n",
    "            '>', '<', '/']\n",
    "    for sep in seps:\n",
    "        new_toks = []\n",
    "        for tok in tokens:\n",
    "            new_toks += tok.split(sep)\n",
    "        tokens = new_toks\n",
    "    \n",
    "    # (4.13) Remove remaining abbreviations\n",
    "    tokens = [tok for tok in tokens if not re.search(\"[a-zA-Z]\\.[a-zA-Z]\\.\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\+\", tok)]\n",
    "    \n",
    "    # Remove punc and small words (e.g. 'a', 'P', 'mm')\n",
    "    punc_to_skip = set(['±', '=', '>', '<'])\n",
    "    tokens = [tok for tok in tokens if tok not in punc_to_skip]     # can skip?\n",
    "    tokens = [tok for tok in tokens if len(tok) > 3]    \n",
    "       \n",
    "    # Unify to lowercase (to simplify matching)\n",
    "    tokens = [tok.lower() for tok in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance of preprocessing function\n",
    "toks_unique = find_tokens_unique_to_one_doc(5)\n",
    "toks_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6c902",
   "metadata": {},
   "source": [
    "### (4.13) Comparing tokens not specific to one doc or corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tokens found in 2+ docs in JP-EN\n",
    "\n",
    "tokens_shared_jpen = []\n",
    "\n",
    "for i in tqdm(jpen_i):\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = preprocess_tok(doc_i)\n",
    "    tokens_i_unique = find_tokens_unique_to_one_doc(i)\n",
    "    tokens_shared_i = [tok for tok in tokens_i if tok not in set(tokens_i_unique)]\n",
    "    for tok in tokens_shared_i:\n",
    "        tokens_shared_jpen.append(tok)\n",
    "\n",
    "tokens_shared_jpen_unique = unique(tokens_shared_jpen) # remove duplicates\n",
    "\n",
    "print(f'Non-document-specific tokens in JP-EN: {len(tokens_shared_jpen_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2945e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tokens found in 2+ docs in EN-EN\n",
    "\n",
    "tokens_shared_enen = []\n",
    "\n",
    "for i in tqdm(enen_i):\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = preprocess_tok(doc_i)\n",
    "    tokens_i_unique = find_tokens_unique_to_one_doc(i)\n",
    "    tokens_shared_i = [tok for tok in tokens_i if tok not in set(tokens_i_unique)]\n",
    "    for tok in tokens_shared_i:\n",
    "        tokens_shared_enen.append(tok)\n",
    "\n",
    "tokens_shared_enen_unique = unique(tokens_shared_enen)\n",
    "print(f'Non-document-specific tokens in EN-EN: {len(tokens_shared_enen_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0161ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection of tokens appearing in ≧4 docs (≧2 in each corpus) \n",
    "\n",
    "toks_to_analyze = [tok for tok in tokens_shared_jpen_unique if tok in set(tokens_shared_enen_unique)]\n",
    "print(f'{len(toks_to_analyze)} tokens to analyze')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54439a4",
   "metadata": {},
   "source": [
    "### (4.13) Get token counts for selected tokens\n",
    "(Needed to run overnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0422ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token counts for every token of interest in every RA in each corpus\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "docs_df = initialize_results_df()\n",
    "toks_df = pd.DataFrame()\n",
    "\n",
    "for tok in tqdm(toks_to_analyze):\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        doc = nlp(text)\n",
    "        toks_in_doc = preprocess_tok(doc)\n",
    "        counter = 0\n",
    "        for doctok in toks_in_doc:\n",
    "            if str(doctok) == str(tok):\n",
    "                counter += 1\n",
    "        docs_df.loc[i, \"count\"] = counter\n",
    "        docs_df.loc[i, \"count_adj\"] = (counter / docs_df.loc[i, 'Word Count']) * 1000  # per 1000 words\n",
    "    \n",
    "    # Separate values by group (JP-EN v. EN-EN)\n",
    "    jp_ct    = list(docs_df[docs_df['Group'] == 'JP-EN'].loc[:, \"count\"])\n",
    "    jp_ctadj = list(docs_df[docs_df['Group'] == 'JP-EN'].loc[:, \"count_adj\"])\n",
    "    en_ct    = list(docs_df[docs_df['Group'] == 'EN-EN'].loc[:, \"count\"])\n",
    "    en_ctadj = list(docs_df[docs_df['Group'] == 'EN-EN'].loc[:, \"count_adj\"])\n",
    "    \n",
    "    # Calculate means and run t-tests\n",
    "    jp_ct_mean    = np.mean(jp_ct)\n",
    "    jp_ctadj_mean = np.mean(jp_ctadj)\n",
    "    en_ct_mean    = np.mean(en_ct)\n",
    "    en_ctadj_mean = np.mean(en_ctadj)\n",
    "        \n",
    "    P_ct    = ttest_ind(jp_ct, en_ct).pvalue\n",
    "    P_ctadj = ttest_ind(jp_ctadj, en_ctadj).pvalue\n",
    "    \n",
    "    # Add to DF\n",
    "    entry = {'Token': tok,\n",
    "             'JP-EN Mean Count': jp_ct_mean, 'JP-EN Mean Freq': jp_ctadj_mean,\n",
    "             'EN-EN Mean Count': en_ct_mean, 'EN-EN Mean Freq': en_ctadj_mean,\n",
    "             'P (count)': P_ct, 'P (freq)': P_ctadj}\n",
    "    toks_df = toks_df.append(entry, ignore_index = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_df.to_pickle('savefiles/toksdf_20220413.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d817c",
   "metadata": {},
   "source": [
    "### Word-level analysis (4/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_df = pd.read_pickle('savefiles/toksdf_20220413.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8165171",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmas more common in JP-EN than EN-EN\n",
    "toks_jp = toks_df[(toks_df[\"JP-EN Mean Freq\"] > toks_df[\"EN-EN Mean Freq\"]) &\n",
    "                 (toks_df[\"JP-EN Mean Count\"] >= 1)]\n",
    "toks_jp.sort_values(\"P (freq)\", inplace=True)\n",
    "results_tokjp = toks_jp[[\"Token\", \"JP-EN Mean Freq\",\n",
    "                         \"EN-EN Mean Freq\", \"P (freq)\"]].reset_index(drop=True)\n",
    "results_tokjp[:40].to_csv(\"savefiles/results_tokjp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmas less common in JP-EN than EN-EN\n",
    "toks_en = toks_df[(toks_df[\"JP-EN Mean Freq\"] < toks_df[\"EN-EN Mean Freq\"]) &\n",
    "                 (toks_df[\"EN-EN Mean Count\"] >= 1)]\n",
    "toks_en.sort_values(\"P (freq)\", inplace=True)\n",
    "results_token = toks_en[[\"Token\", \"JP-EN Mean Freq\",\n",
    "                         \"EN-EN Mean Freq\", \"P (freq)\"]].reset_index(drop=True)\n",
    "results_token[:40].to_csv(\"savefiles/results_token.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e1194",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f7bd13a",
   "metadata": {},
   "source": [
    "## Statistical testing\n",
    "#### 1. Type/token ratio (lexical diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a156961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(doc):\n",
    "    \n",
    "    token_list = preprocess_tok(doc)\n",
    "    n_type = len(unique(token_list))\n",
    "    n_token = len(token_list)\n",
    "    ttr = n_type/n_token\n",
    "    \n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4497a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(var):\n",
    "    \n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    jp_stats = list(results_df[results_df['Group'] == 'JP-EN'].loc[:, var])\n",
    "    en_stats = list(results_df[results_df['Group'] == 'EN-EN'].loc[:, var])\n",
    "    P = ttest_ind(jp_stats, en_stats).pvalue\n",
    "    \n",
    "    print(f'Mean {var}, JP-EN:  {np.mean(jp_stats)}')\n",
    "    print(f'Mean {var}, EN-EN:  {np.mean(en_stats)}')\n",
    "    print(f'Sig. (unpaired t-test): {P}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b02f3a39",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Type/Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JP-EN</td>\n",
       "      <td>Tamura</td>\n",
       "      <td>Neural Network Development in L</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>0.261733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JP-EN</td>\n",
       "      <td>Watanabe</td>\n",
       "      <td>Diminished Medial Prefrontal Ac</td>\n",
       "      <td>6918.0</td>\n",
       "      <td>0.218375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN-EN</td>\n",
       "      <td>Sobhani</td>\n",
       "      <td>Interpersonal Liking Modulates</td>\n",
       "      <td>5953.0</td>\n",
       "      <td>0.260666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN-EN</td>\n",
       "      <td>Majdandžić</td>\n",
       "      <td>The Human Factor: Behavioral an</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>0.233118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN-EN</td>\n",
       "      <td>Dixon</td>\n",
       "      <td>The Decision to Engage Cognitiv</td>\n",
       "      <td>8620.0</td>\n",
       "      <td>0.217311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group      Author                            Title  Word Count  Type/Token\n",
       "0  JP-EN      Tamura  Neural Network Development in L      6926.0    0.261733\n",
       "1  JP-EN    Watanabe  Diminished Medial Prefrontal Ac      6918.0    0.218375\n",
       "2  EN-EN     Sobhani  Interpersonal Liking Modulates       5953.0    0.260666\n",
       "3  EN-EN  Majdandžić  The Human Factor: Behavioral an      9587.0    0.233118\n",
       "4  EN-EN       Dixon  The Decision to Engage Cognitiv      8620.0    0.217311"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate raw type/token ratio (lemmatized)\n",
    "\n",
    "results_df = initialize_results_df()\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Run scispaCy model\n",
    "    doc = nlp(text)\n",
    "    # Preprocess\n",
    "    ttr = type_token_ratio(doc)\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Type/Token'] = ttr\n",
    "\n",
    "# Calculate adjusted type/token ratio (lemmatized) divided by word count\n",
    "\n",
    "# Divide by mean word count of all documents\n",
    "results_df['TTR_adj'] = (results_df['Type/Token'] / results_df['Word Count']) * 10000\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c82bf425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Type/Token, JP-EN:  0.24102634474435575\n",
      "Mean Type/Token, EN-EN:  0.25306356406579766\n",
      "Sig. (unpaired t-test): 0.3898003303172157\n",
      "\n",
      "\n",
      "Mean Word Count, JP-EN:  6852.3\n",
      "Mean Word Count, EN-EN:  6453.2\n",
      "Sig. (unpaired t-test): 0.5616242355640981\n",
      "\n",
      "\n",
      "Mean TTR_adj, JP-EN:  0.3693009163913344\n",
      "Mean TTR_adj, EN-EN:  0.42663807247111507\n",
      "Sig. (unpaired t-test): 0.37048811653384883\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare mean stats between JP-EN and EN-EN corpora\n",
    "\n",
    "compare_means('Type/Token')\n",
    "compare_means('Word Count')\n",
    "compare_means('TTR_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9949952",
   "metadata": {},
   "source": [
    "Comments (4/10): H1 seems to be rejected. fMRI studies authored by Japanese scientists are just as lexically sophisticated as comparable docs authored by Anglophone counterparts. Perhaps this is a good thing: i.e., any differences discovered later are a product of linguistic features, rather than scientific knowledge/ignorance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4959e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2bdb554",
   "metadata": {},
   "source": [
    "## N-gram comparisons\n",
    "### For comparing 1-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d84c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexeme_counter(doc, string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for getting raw lemma count in a document.\n",
    "    \"\"\"\n",
    "        \n",
    "    tokens = preprocess_tok(doc)\n",
    "    counter = 0\n",
    "    for tok in tokens:\n",
    "        if str(tok) == str(string):\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc01426",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "\n",
    "for lexeme in [\"think\", \"consider\", \"report\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme)\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    \n",
    "    for i in range(0,20):\n",
    "        # Pull text from df\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        # Run scispaCy model\n",
    "        doc = nlp(text)\n",
    "        # Count lexeme (includes preprocessing)\n",
    "        ct = lexeme_counter(doc, lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means('n_think')\n",
    "compare_means('n_consider')\n",
    "compare_means('n_think_adj')\n",
    "compare_means('n_consider_adj')\n",
    "compare_means('n_report')\n",
    "compare_means('n_report_adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    results_df.loc[i, 'Combined'] = results_df.loc[i, 'n_think'] + results_df.loc[i, 'n_consider']\n",
    "    results_df.loc[i, 'Combined_adj'] = results_df.loc[i, 'Combined'] / results_df.loc[i, 'Word Count']\n",
    "    \n",
    "compare_means('Combined')\n",
    "compare_means('Combined_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0552d",
   "metadata": {},
   "source": [
    "### For comparing 2+ grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "cols = []\n",
    "\n",
    "for lexeme in [\"in this study\", \"therefore\", \"in addition\", \"bold response\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme.replace(\" \", \"\"))\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    cols.append(new_name_n)\n",
    "    cols.append(new_name_adj)\n",
    "\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"].lower()\n",
    "        ct = text.count(lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    compare_means(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582371e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
