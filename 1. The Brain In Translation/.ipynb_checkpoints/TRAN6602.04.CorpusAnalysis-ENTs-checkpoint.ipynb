{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d386e32e",
   "metadata": {},
   "source": [
    "#### (4月18日) Corpus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99017208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Row indices of docs in respective corpora\n",
    "jpen_i = [0,  1,  5, 10, 11, 12, 13, 14, 17, 19]\n",
    "enen_i = [2,  3,  4,  6,  7,  8,  9, 15, 16, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle\n",
    "corpus_new = pd.read_pickle('savefiles/corpusfull_20220410.pkl')\n",
    "toks_df = pd.read_pickle('savefiles/toksdf_20220413.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ce66a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3v/knnfgj_54zj0mypk_ds4wm_h0000gn/T/ipykernel_17122/2935863018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Preprocess each doc before Spacy modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcorpus_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Project-Portfolio/1. The Brain In Translation/functions.py\u001b[0m in \u001b[0;36mpreprocess_gen\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\u200a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# remove weird space code, newlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\[(\\d+)\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# remove refs ([1], [23], etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare df for scispaCy\n",
    "from functions import collapse, preprocess_gen, initialize_results_df\n",
    "\n",
    "# Converts each doc from list of paras to one long string\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = collapse(corpus_new.loc[i, \"Text\"])\n",
    "\n",
    "# Preprocess each doc before Spacy modeling\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = preprocess_gen(corpus_new.loc[i, \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0343fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inspecting single texts\n",
    "# text = corpus_new.loc[0, \"Text\"]\n",
    "# text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92036ceb",
   "metadata": {},
   "source": [
    "#### Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fabb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import unique, find_tokens_unique_to_one_doc\n",
    "\n",
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tok(doc):\n",
    "    \n",
    "    # Collect lemmas not tagged by spaCy as 1. punctuation, 2. digits, 3. URLs, or 4. stop words\n",
    "    tokens = [tok.lemma_ for tok in doc if not (tok.is_punct | tok.is_digit | tok.like_url | tok.is_stop)]\n",
    "    \n",
    "    # Remove any tokens containing mid-string digits (e.g. \"P5-a\") or punc ('t(are')\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\d\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\(\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\)\", tok)]\n",
    "    \n",
    "    # (4.13) Break apart hyphen- or slash-separated compounds\n",
    "    seps = ['-', '–', '―',\n",
    "            ';', ':',\n",
    "            '\\]', '\\[', \n",
    "            '’', '”', \n",
    "            '>', '<', '/']\n",
    "    for sep in seps:\n",
    "        new_toks = []\n",
    "        for tok in tokens:\n",
    "            new_toks += tok.split(sep)\n",
    "        tokens = new_toks\n",
    "    \n",
    "    # (4.13) Remove remaining abbreviations\n",
    "    tokens = [tok for tok in tokens if not re.search(\"[a-zA-Z]\\.[a-zA-Z]\\.\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\+\", tok)]\n",
    "    \n",
    "    # Remove punc and small words (e.g. 'a', 'P', 'mm')\n",
    "    punc_to_skip = set(['±', '=', '>', '<'])\n",
    "    tokens = [tok for tok in tokens if tok not in punc_to_skip]     # can skip?\n",
    "    tokens = [tok for tok in tokens if len(tok) > 3]    \n",
    "       \n",
    "    # Unify to lowercase (to simplify matching)\n",
    "    tokens = [tok.lower() for tok in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance of preprocessing function\n",
    "toks_unique = find_tokens_unique_to_one_doc(5)\n",
    "toks_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6c902",
   "metadata": {},
   "source": [
    "### (4.13) Comparing tokens not specific to one doc or corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tokens found in 2+ docs in JP-EN\n",
    "\n",
    "tokens_shared_jpen = []\n",
    "\n",
    "for i in tqdm(jpen_i):\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = preprocess_tok(doc_i)\n",
    "    tokens_i_unique = find_tokens_unique_to_one_doc(i)\n",
    "    tokens_shared_i = [tok for tok in tokens_i if tok not in set(tokens_i_unique)]\n",
    "    for tok in tokens_shared_i:\n",
    "        tokens_shared_jpen.append(tok)\n",
    "\n",
    "tokens_shared_jpen_unique = unique(tokens_shared_jpen) # remove duplicates\n",
    "\n",
    "print(f'Non-document-specific tokens in JP-EN: {len(tokens_shared_jpen_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2945e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tokens found in 2+ docs in EN-EN\n",
    "\n",
    "tokens_shared_enen = []\n",
    "\n",
    "for i in tqdm(enen_i):\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = preprocess_tok(doc_i)\n",
    "    tokens_i_unique = find_tokens_unique_to_one_doc(i)\n",
    "    tokens_shared_i = [tok for tok in tokens_i if tok not in set(tokens_i_unique)]\n",
    "    for tok in tokens_shared_i:\n",
    "        tokens_shared_enen.append(tok)\n",
    "\n",
    "tokens_shared_enen_unique = unique(tokens_shared_enen)\n",
    "print(f'Non-document-specific tokens in EN-EN: {len(tokens_shared_enen_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0161ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection of tokens appearing in ≧4 docs (≧2 in each corpus) \n",
    "\n",
    "toks_to_analyze = [tok for tok in tokens_shared_jpen_unique if tok in set(tokens_shared_enen_unique)]\n",
    "print(f'{len(toks_to_analyze)} tokens to analyze')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54439a4",
   "metadata": {},
   "source": [
    "### (4.13) Run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0422ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Kahuna\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "docs_df = initialize_results_df()\n",
    "toks_df = pd.DataFrame()\n",
    "\n",
    "for tok in tqdm(toks_to_analyze):\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        doc = nlp(text)\n",
    "        toks_in_doc = preprocess_tok(doc)\n",
    "        counter = 0\n",
    "        for doctok in toks_in_doc:\n",
    "            if str(doctok) == str(tok):\n",
    "                counter += 1\n",
    "        docs_df.loc[i, \"count\"] = counter\n",
    "        docs_df.loc[i, \"count_adj\"] = (counter / docs_df.loc[i, 'Word Count']) * 1000  # per 1000 words\n",
    "    \n",
    "    # Separate values by group (JP-EN v. EN-EN)\n",
    "    jp_ct    = list(docs_df[docs_df['Group'] == 'JP-EN'].loc[:, \"count\"])\n",
    "    jp_ctadj = list(docs_df[docs_df['Group'] == 'JP-EN'].loc[:, \"count_adj\"])\n",
    "    en_ct    = list(docs_df[docs_df['Group'] == 'EN-EN'].loc[:, \"count\"])\n",
    "    en_ctadj = list(docs_df[docs_df['Group'] == 'EN-EN'].loc[:, \"count_adj\"])\n",
    "    \n",
    "    # Calculate means and run t-tests\n",
    "    jp_ct_mean    = np.mean(jp_ct)\n",
    "    jp_ctadj_mean = np.mean(jp_ctadj)\n",
    "    en_ct_mean    = np.mean(en_ct)\n",
    "    en_ctadj_mean = np.mean(en_ctadj)\n",
    "        \n",
    "    P_ct    = ttest_ind(jp_ct, en_ct).pvalue\n",
    "    P_ctadj = ttest_ind(jp_ctadj, en_ctadj).pvalue\n",
    "    \n",
    "    # Add to DF\n",
    "    entry = {'Token': tok,\n",
    "             'JP-EN Mean Count': jp_ct_mean, 'JP-EN Mean Freq': jp_ctadj_mean,\n",
    "             'EN-EN Mean Count': en_ct_mean, 'EN-EN Mean Freq': en_ctadj_mean,\n",
    "             'P (count)': P_ct, 'P (freq)': P_ctadj}\n",
    "    toks_df = toks_df.append(entry, ignore_index = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_df.to_pickle('savefiles/entsdf_20220418.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f454aa4",
   "metadata": {},
   "source": [
    "### Token-level analysis (4/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_df = pd.read_pickle('savefiles/toksdf_20220418.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72843f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmas more common in JP-EN than EN-EN\n",
    "toks_jp = toks_df[toks_df[\"JP-EN Mean Freq\"] > toks_df[\"EN-EN Mean Freq\"]]\n",
    "toks_jp.sort_values(\"P (freq)\").head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5288088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5905ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Still need to sort_values by P-value\n",
    "toks_df.sort_values(\"P (freq)\").head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmas less common in JP-EN than EN-EN\n",
    "toks_en = toks_df[toks_df[\"JP-EN Mean Freq\"] < toks_df[\"EN-EN Mean Freq\"]]\n",
    "toks_en.sort_values(\"P (freq)\").head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb67db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox\n",
    "\n",
    "# new_words1, new_words2 = [], []\n",
    "# words = ['gyrus', 'parietal-temporal-occipital', 'anxiety/depression']\n",
    "# for word in words:\n",
    "#     new_words += word.split('-')\n",
    "\n",
    "# new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e1194",
   "metadata": {},
   "source": [
    "### For counting 1-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6494c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexeme_counter(doc, string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for getting raw lemma count in a document.\n",
    "    \"\"\"\n",
    "        \n",
    "    tokens = preprocess_tok(doc)\n",
    "    counter = 0\n",
    "    for tok in tokens:\n",
    "        if str(tok) == str(string):\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276eba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "\n",
    "for lexeme in [\"think\", \"consider\", \"report\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme)\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    \n",
    "    for i in range(0,20):\n",
    "        # Pull text from df\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        # Run scispaCy model\n",
    "        doc = nlp(text)\n",
    "        # Count lexeme (includes preprocessing)\n",
    "        ct = lexeme_counter(doc, lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means('n_think')\n",
    "compare_means('n_consider')\n",
    "compare_means('n_think_adj')\n",
    "compare_means('n_consider_adj')\n",
    "compare_means('n_report')\n",
    "compare_means('n_report_adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf87b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    results_df.loc[i, 'Combined'] = results_df.loc[i, 'n_think'] + results_df.loc[i, 'n_consider']\n",
    "    results_df.loc[i, 'Combined_adj'] = results_df.loc[i, 'Combined'] / results_df.loc[i, 'Word Count']\n",
    "    \n",
    "compare_means('Combined')\n",
    "compare_means('Combined_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20992527",
   "metadata": {},
   "source": [
    "### For 2,3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "cols = []\n",
    "\n",
    "for lexeme in [\"in this study\", \"therefore\", \"in addition\", \"bold response\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme.replace(\" \", \"\"))\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    cols.append(new_name_n)\n",
    "    cols.append(new_name_adj)\n",
    "\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"].lower()\n",
    "        ct = text.count(lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad86023",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    compare_means(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7bd13a",
   "metadata": {},
   "source": [
    "### Statistical testing\n",
    "#### 1. Type/token ratio (lexical diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(doc):\n",
    "    \n",
    "    token_list = preprocess_tok(doc)\n",
    "    n_type = len(unique(token_list))\n",
    "    n_token = len(token_list)\n",
    "    ttr = n_type/n_token\n",
    "    \n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4497a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(var):\n",
    "    \n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    jp_stats = list(results_df[results_df['Group'] == 'JP-EN'].loc[:, var])\n",
    "    en_stats = list(results_df[results_df['Group'] == 'EN-EN'].loc[:, var])\n",
    "    P = ttest_ind(jp_stats, en_stats).pvalue\n",
    "    \n",
    "    print(f'Mean {var}, JP-EN:  {np.mean(jp_stats)}')\n",
    "    print(f'Mean {var}, EN-EN:  {np.mean(en_stats)}')\n",
    "    print(f'Sig. (unpaired t-test): {P}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate raw type/token ratio (lemmatized)\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Run scispaCy model\n",
    "    doc = nlp(text)\n",
    "    # Preprocess\n",
    "    ttr = type_token_ratio(doc)\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Type/Token'] = ttr\n",
    "\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted type/token ratio (lemmatized) divided by word count\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Split by word (\" \" for simplicity)\n",
    "    word_ct = len(text.split(' '))\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Word Count'] = word_ct\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by mean word count of all documents\n",
    "results_df['TTR_adj'] = (results_df['Type/Token'] / results_df['Word Count']) * np.mean(results_df['Word Count'])\n",
    "    \n",
    "results_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean stats between JP-EN and EN-EN corpora\n",
    "\n",
    "compare_means('Type/Token')\n",
    "compare_means('Word Count')\n",
    "compare_means('TTR_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9949952",
   "metadata": {},
   "source": [
    "Comments (4/10): H1 seems to be rejected. fMRI studies authored by Japanese scientists are just as lexically sophisticated as comparable docs authored by Anglophone counterparts. Perhaps this is a good thing: i.e., any differences discovered later are a product of linguistic features, rather than scientific knowledge/ignorance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4959e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610f4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d84c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the entities extracted by the mention detector. Note that they don't have types\n",
    "# like in SpaCy, and they are more general (e.g including verbs) - these are any spans\n",
    "# which might be an entity in UMLS, a large biomedical database.\n",
    "print(a.ents)\n",
    "\n",
    "\n",
    "#>>> (Myeloid derived suppressor cells,\n",
    "#     MDSC,\n",
    "#     immature,\n",
    "#     myeloid cells,\n",
    "#     immunosuppressive activity,\n",
    "#     accumulate,\n",
    "#     tumor-bearing mice,\n",
    "#     humans,\n",
    "#     cancer,\n",
    "#     hepatocellular carcinoma,\n",
    "#     HCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ac3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also visualise dependency parses\n",
    "# (This renders automatically inside a jupyter notebook!):\n",
    "from spacy import displacy\n",
    "# displacy.render(next(doc2.sents), style='dep', jupyter=True)\n",
    "displacy.render(a, style='dep', jupyter=True)\n",
    "\n",
    "# See below for the generated SVG.\n",
    "# Zoom your browser in a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc01426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1887e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd250a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa559c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d1a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582371e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15373c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be52c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2734ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba911c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7371bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8562bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71c0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
