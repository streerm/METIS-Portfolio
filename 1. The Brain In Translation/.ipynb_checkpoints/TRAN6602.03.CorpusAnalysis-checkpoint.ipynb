{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d386e32e",
   "metadata": {},
   "source": [
    "#### (4月12日) Corpus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99017208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle\n",
    "corpus_new = pd.read_pickle('savefiles/corpusfull_20220410.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8e24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Paragraphs extracted from XML files contain different numbers of sentences,\n",
    "    and even incomplete sentences. This function collapses a list of paragraphs\n",
    "    into a list of sentences or sentence-equivalents in advance of NLP processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_raw = \"\"\n",
    "    punc = set([\".\", \",\", \";\", \":\"])\n",
    "    for i, para in enumerate(text):\n",
    "        if para[-1] in punc:\n",
    "            doc_raw += (para + \" \")\n",
    "        else:\n",
    "            doc_raw += (para + \". \")\n",
    "        \n",
    "    return doc_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2f00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gen(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is primarily for removing references, and fixing spacing\n",
    "    between/within sentences in preparation for scispaCy language modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.replace('\\u200a', '').replace('\\n', '')   # remove weird space code, newlines\n",
    "    text = re.sub('\\[(\\d+)\\]', '', text)                  # remove refs ([1], [23], etc.)\n",
    "    text = text.replace(' ,', '').replace(' .', '.')      # fix spaces created by prev line\n",
    "    text = text.replace(' ;', ';').replace(' :', ':')     # \n",
    "    text = text.replace('  ', ' ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37e6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts each doc from list of paras to one long string\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = collapse(corpus_new.loc[i, \"Text\"])\n",
    "\n",
    "# Preprocess each doc before Spacy modeling\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = preprocess_gen(corpus_new.loc[i, \"Text\"])\n",
    "    \n",
    "# For practicing on single texts\n",
    "# text = corpus_new.loc[0, \"Text\"]\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeefcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row indices of docs in respective corpora\n",
    "jpen_i = [0,  1,  5, 10, 11, 12, 13, 14, 17, 19]\n",
    "enen_i = [2,  3,  4,  6,  7,  8,  9, 15, 16, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fdfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_results_df():\n",
    "    \n",
    "    \"\"\"\n",
    "    Results DF should be reset for every hypothesis tested.\n",
    "    Note: Run BEFORE preprocess_tok to capture unanalyzed tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    results_df = corpus_new[['Group', 'Author', 'Title']]\n",
    "    results_df['Title'] = pd.Series([title[:31] for title in results_df['Title']])  # prune title for readability\n",
    "    \n",
    "    # with word count\n",
    "    for i in range(0,20):\n",
    "        # Pull text from df\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        # Split by word (\" \" for simplicity)\n",
    "        word_ct = len(text.split(' '))\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, 'Word Count'] = word_ct\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92036ceb",
   "metadata": {},
   "source": [
    "#### Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fabb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43e3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(ls):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a list of unique items from an existing list.\n",
    "    \"\"\"\n",
    " \n",
    "    unique_list = []\n",
    "     \n",
    "    for x in ls:\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f0b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tok(doc):\n",
    "    \n",
    "    # Collect lemmas not tagged by spaCy as 1. punctuation, 2. digits, 3. URLs, or 4. stop words\n",
    "    tokens = [tok.lemma_ for tok in doc if not (tok.is_punct | tok.is_digit | tok.like_url | tok.is_stop)]\n",
    "    \n",
    "    # Remove any tokens containing mid-string digits (e.g. \"P5-a\") or punc ('t(are')\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\d\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\(\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\)\", tok)]\n",
    "    \n",
    "    # (4.13) Break apart hyphen- or slash-separated compounds\n",
    "    seps = ['-', '–', '―',\n",
    "            ';', ':',\n",
    "            '\\]', '\\[', \n",
    "            '’', '”', \n",
    "            '>', '<', '/']\n",
    "    for sep in seps:\n",
    "        new_toks = []\n",
    "        for tok in tokens:\n",
    "            new_toks += tok.split(sep)\n",
    "        tokens = new_toks\n",
    "    \n",
    "    # (4.13) Remove remaining abbreviations\n",
    "    tokens = [tok for tok in tokens if not re.search(\"[a-zA-Z]\\.[a-zA-Z]\\.\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\+\", tok)]\n",
    "    \n",
    "    # Remove punc and small words (e.g. 'a', 'P', 'mm')\n",
    "    punc_to_skip = set(['±', '=', '>', '<'])\n",
    "    tokens = [tok for tok in tokens if tok not in punc_to_skip]     # can skip?\n",
    "    tokens = [tok for tok in tokens if len(tok) > 3]    \n",
    "       \n",
    "    # Unify to lowercase (to simplify matching)\n",
    "    tokens = [tok.lower() for tok in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b54c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tokens_unique_to_one_doc(i):\n",
    "    \n",
    "    other_docs = list(range(0,20))\n",
    "    other_docs.remove(i)\n",
    "    \n",
    "    # Doc in question\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = unique(preprocess_tok(doc_i))\n",
    "    \n",
    "    # Iterate thru all 19 other docs\n",
    "    for j in other_docs:\n",
    "        text_j = corpus_new.loc[j, \"Text\"]\n",
    "        doc_j = nlp(text_j)\n",
    "        tokens_j = set(unique(preprocess_tok(doc_j)))\n",
    "        \n",
    "        for tok in tokens_i:\n",
    "            if tok in tokens_j:\n",
    "                tokens_i.remove(tok)\n",
    "    \n",
    "    return tokens_i            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance of preprocessing function\n",
    "toks_unique = find_tokens_unique_to_one_doc(5)\n",
    "toks_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6c902",
   "metadata": {},
   "source": [
    "### (4.13) Comparing tokens not specific to one doc or corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e07b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [04:23<00:00, 26.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-document-specific tokens in JP-EN: 2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect all tokens found in 2+ docs in JP-EN\n",
    "\n",
    "tokens_shared_jpen = []\n",
    "\n",
    "for i in tqdm(jpen_i):\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = preprocess_tok(doc_i)\n",
    "    tokens_i_unique = find_tokens_unique_to_one_doc(i)\n",
    "    tokens_shared_i = [tok for tok in tokens_i if tok not in set(tokens_i_unique)]\n",
    "    for tok in tokens_shared_i:\n",
    "        tokens_shared_jpen.append(tok)\n",
    "\n",
    "tokens_shared_jpen_unique = unique(tokens_shared_jpen) # remove duplicates\n",
    "\n",
    "print(f'Non-document-specific tokens in JP-EN: {len(tokens_shared_jpen_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2945e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [04:20<00:00, 26.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-document-specific tokens in EN-EN: 2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect all tokens found in 2+ docs in EN-EN\n",
    "\n",
    "tokens_shared_enen = []\n",
    "\n",
    "for i in tqdm(enen_i):\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = preprocess_tok(doc_i)\n",
    "    tokens_i_unique = find_tokens_unique_to_one_doc(i)\n",
    "    tokens_shared_i = [tok for tok in tokens_i if tok not in set(tokens_i_unique)]\n",
    "    for tok in tokens_shared_i:\n",
    "        tokens_shared_enen.append(tok)\n",
    "\n",
    "tokens_shared_enen_unique = unique(tokens_shared_enen)\n",
    "print(f'Non-document-specific tokens in EN-EN: {len(tokens_shared_enen_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc0161ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849 tokens to analyze\n"
     ]
    }
   ],
   "source": [
    "# Find intersection of tokens appearing in ≧4 docs (≧2 in each corpus) \n",
    "\n",
    "toks_to_analyze = [tok for tok in tokens_shared_jpen_unique if tok in set(tokens_shared_enen_unique)]\n",
    "print(f'{len(toks_to_analyze)} tokens to analyze')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54439a4",
   "metadata": {},
   "source": [
    "### (4.13) Run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0422ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1849/1849 [12:45:28<00:00, 24.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# Big Kahuna\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "docs_df = initialize_results_df()\n",
    "toks_df = pd.DataFrame()\n",
    "\n",
    "for tok in tqdm(toks_to_analyze):\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        doc = nlp(text)\n",
    "        toks_in_doc = preprocess_tok(doc)\n",
    "        counter = 0\n",
    "        for doctok in toks_in_doc:\n",
    "            if str(doctok) == str(tok):\n",
    "                counter += 1\n",
    "        docs_df.loc[i, \"count\"] = counter\n",
    "        docs_df.loc[i, \"count_adj\"] = (counter / docs_df.loc[i, 'Word Count']) * 1000  # per 1000 words\n",
    "    \n",
    "    # Separate values by group (JP-EN v. EN-EN)\n",
    "    jp_ct    = list(docs_df[docs_df['Group'] == 'JP-EN'].loc[:, \"count\"])\n",
    "    jp_ctadj = list(docs_df[docs_df['Group'] == 'JP-EN'].loc[:, \"count_adj\"])\n",
    "    en_ct    = list(docs_df[docs_df['Group'] == 'EN-EN'].loc[:, \"count\"])\n",
    "    en_ctadj = list(docs_df[docs_df['Group'] == 'EN-EN'].loc[:, \"count_adj\"])\n",
    "    \n",
    "    # Calculate means and run t-tests\n",
    "    jp_ct_mean    = np.mean(jp_ct)\n",
    "    jp_ctadj_mean = np.mean(jp_ctadj)\n",
    "    en_ct_mean    = np.mean(en_ct)\n",
    "    en_ctadj_mean = np.mean(en_ctadj)\n",
    "        \n",
    "    P_ct    = ttest_ind(jp_ct, en_ct).pvalue\n",
    "    P_ctadj = ttest_ind(jp_ctadj, en_ctadj).pvalue\n",
    "    \n",
    "    # Add to DF\n",
    "    entry = {'Token': tok,\n",
    "             'JP-EN Mean Count': jp_ct_mean, 'JP-EN Mean Freq': jp_ctadj_mean,\n",
    "             'EN-EN Mean Count': en_ct_mean, 'EN-EN Mean Freq': en_ctadj_mean,\n",
    "             'P (count)': P_ct, 'P (freq)': P_ctadj}\n",
    "    toks_df = toks_df.append(entry, ignore_index = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a4e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_df.to_pickle('savefiles/toksdf_20220413.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5905ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>JP-EN Mean Count</th>\n",
       "      <th>JP-EN Mean Freq</th>\n",
       "      <th>EN-EN Mean Count</th>\n",
       "      <th>EN-EN Mean Freq</th>\n",
       "      <th>P (count)</th>\n",
       "      <th>P (freq)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>detailed</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.170757</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>obtain</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.599597</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.195152</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.008790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>explore</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.232113</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.011141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>common</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.586217</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>0.011672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>list</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.162510</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.012019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>thickness</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.184369</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.013301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>parametric</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.361579</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.036445</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>0.014723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>respectively</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.832330</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.132969</td>\n",
       "      <td>0.035646</td>\n",
       "      <td>0.019794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>adopt</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>0.025988</td>\n",
       "      <td>0.020350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>activate</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.107028</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.226077</td>\n",
       "      <td>0.034104</td>\n",
       "      <td>0.021462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>study</td>\n",
       "      <td>40.9</td>\n",
       "      <td>6.115922</td>\n",
       "      <td>24.6</td>\n",
       "      <td>4.143915</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>alternative</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.131495</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>0.025221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>enhance</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.388717</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.088260</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.026860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>active</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.079231</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.425237</td>\n",
       "      <td>0.039044</td>\n",
       "      <td>0.028967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>remove</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.205185</td>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.031685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>sphere</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.179215</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.052909</td>\n",
       "      <td>0.057584</td>\n",
       "      <td>0.031699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>medial</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.699221</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.277912</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.034557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>detection</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.124554</td>\n",
       "      <td>0.045270</td>\n",
       "      <td>0.039317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>fill</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.054115</td>\n",
       "      <td>0.042676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>projection</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.098515</td>\n",
       "      <td>0.054115</td>\n",
       "      <td>0.043092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Token  JP-EN Mean Count  JP-EN Mean Freq  EN-EN Mean Count  \\\n",
       "672       detailed               1.2         0.170757               0.2   \n",
       "888         obtain               4.3         0.599597               1.4   \n",
       "1284       explore               0.2         0.028621               1.4   \n",
       "286         common               4.0         0.586217               0.5   \n",
       "728           list               1.2         0.162510               0.1   \n",
       "426      thickness               1.2         0.184369               0.2   \n",
       "524     parametric               2.5         0.361579               0.3   \n",
       "631   respectively               6.1         0.832330               0.9   \n",
       "798          adopt               1.2         0.152203               0.1   \n",
       "720       activate               7.6         1.107028               1.5   \n",
       "153          study              40.9         6.115922              24.6   \n",
       "804    alternative               0.1         0.014438               0.8   \n",
       "238        enhance               2.6         0.388717               0.6   \n",
       "723         active               0.5         0.079231               2.8   \n",
       "984         remove               0.5         0.073286               1.3   \n",
       "1002        sphere               1.2         0.179215               0.4   \n",
       "649         medial               4.4         0.699221               1.8   \n",
       "1272     detection               0.1         0.011443               0.7   \n",
       "1208          fill               0.1         0.011443               0.6   \n",
       "1216    projection               0.1         0.011443               0.6   \n",
       "\n",
       "      EN-EN Mean Freq  P (count)  P (freq)  \n",
       "672          0.038129   0.002363  0.005128  \n",
       "888          0.195152   0.022020  0.008790  \n",
       "1284         0.232113   0.007005  0.011141  \n",
       "286          0.072855   0.015005  0.011672  \n",
       "728          0.017790   0.013442  0.012019  \n",
       "426          0.035410   0.010987  0.013301  \n",
       "524          0.036445   0.023064  0.014723  \n",
       "631          0.132969   0.035646  0.019794  \n",
       "798          0.010431   0.025988  0.020350  \n",
       "720          0.226077   0.034104  0.021462  \n",
       "153          4.143915   0.003081  0.024996  \n",
       "804          0.131495   0.017920  0.025221  \n",
       "238          0.088260   0.032196  0.026860  \n",
       "723          0.425237   0.039044  0.028967  \n",
       "984          0.205185   0.046477  0.031685  \n",
       "1002         0.052909   0.057584  0.031699  \n",
       "649          0.277912   0.035680  0.034557  \n",
       "1272         0.124554   0.045270  0.039317  \n",
       "1208         0.088988   0.054115  0.042676  \n",
       "1216         0.098515   0.054115  0.043092  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Still need to sort_values by P-value\n",
    "toks_df.sort_values(\"P (freq)\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a3018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb67db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox\n",
    "\n",
    "# new_words1, new_words2 = [], []\n",
    "# words = ['gyrus', 'parietal-temporal-occipital', 'anxiety/depression']\n",
    "# for word in words:\n",
    "#     new_words += word.split('-')\n",
    "\n",
    "# new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e1194",
   "metadata": {},
   "source": [
    "### For counting 1-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6494c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexeme_counter(doc, string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for getting raw lemma count in a document.\n",
    "    \"\"\"\n",
    "        \n",
    "    tokens = preprocess_tok(doc)\n",
    "    counter = 0\n",
    "    for tok in tokens:\n",
    "        if str(tok) == str(string):\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276eba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "\n",
    "for lexeme in [\"think\", \"consider\", \"report\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme)\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    \n",
    "    for i in range(0,20):\n",
    "        # Pull text from df\n",
    "        text = corpus_new.loc[i, \"Text\"]\n",
    "        # Run scispaCy model\n",
    "        doc = nlp(text)\n",
    "        # Count lexeme (includes preprocessing)\n",
    "        ct = lexeme_counter(doc, lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means('n_think')\n",
    "compare_means('n_consider')\n",
    "compare_means('n_think_adj')\n",
    "compare_means('n_consider_adj')\n",
    "compare_means('n_report')\n",
    "compare_means('n_report_adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf87b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    results_df.loc[i, 'Combined'] = results_df.loc[i, 'n_think'] + results_df.loc[i, 'n_consider']\n",
    "    results_df.loc[i, 'Combined_adj'] = results_df.loc[i, 'Combined'] / results_df.loc[i, 'Word Count']\n",
    "    \n",
    "compare_means('Combined')\n",
    "compare_means('Combined_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20992527",
   "metadata": {},
   "source": [
    "### For 2,3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "cols = []\n",
    "\n",
    "for lexeme in [\"in this study\", \"therefore\", \"in addition\", \"bold response\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme.replace(\" \", \"\"))\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    cols.append(new_name_n)\n",
    "    cols.append(new_name_adj)\n",
    "\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"].lower()\n",
    "        ct = text.count(lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad86023",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    compare_means(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7bd13a",
   "metadata": {},
   "source": [
    "### Statistical testing\n",
    "#### 1. Type/token ratio (lexical diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(doc):\n",
    "    \n",
    "    token_list = preprocess_tok(doc)\n",
    "    n_type = len(unique(token_list))\n",
    "    n_token = len(token_list)\n",
    "    ttr = n_type/n_token\n",
    "    \n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4497a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(var):\n",
    "    \n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    jp_stats = list(results_df[results_df['Group'] == 'JP-EN'].loc[:, var])\n",
    "    en_stats = list(results_df[results_df['Group'] == 'EN-EN'].loc[:, var])\n",
    "    P = ttest_ind(jp_stats, en_stats).pvalue\n",
    "    \n",
    "    print(f'Mean {var}, JP-EN:  {np.mean(jp_stats)}')\n",
    "    print(f'Mean {var}, EN-EN:  {np.mean(en_stats)}')\n",
    "    print(f'Sig. (unpaired t-test): {P}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate raw type/token ratio (lemmatized)\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Run scispaCy model\n",
    "    doc = nlp(text)\n",
    "    # Preprocess\n",
    "    ttr = type_token_ratio(doc)\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Type/Token'] = ttr\n",
    "\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted type/token ratio (lemmatized) divided by word count\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Split by word (\" \" for simplicity)\n",
    "    word_ct = len(text.split(' '))\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Word Count'] = word_ct\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by mean word count of all documents\n",
    "results_df['TTR_adj'] = (results_df['Type/Token'] / results_df['Word Count']) * np.mean(results_df['Word Count'])\n",
    "    \n",
    "results_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean stats between JP-EN and EN-EN corpora\n",
    "\n",
    "compare_means('Type/Token')\n",
    "compare_means('Word Count')\n",
    "compare_means('TTR_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9949952",
   "metadata": {},
   "source": [
    "Comments (4/10): H1 seems to be rejected. fMRI studies authored by Japanese scientists are just as lexically sophisticated as comparable docs authored by Anglophone counterparts. Perhaps this is a good thing: i.e., any differences discovered later are a product of linguistic features, rather than scientific knowledge/ignorance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4959e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610f4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d84c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the entities extracted by the mention detector. Note that they don't have types\n",
    "# like in SpaCy, and they are more general (e.g including verbs) - these are any spans\n",
    "# which might be an entity in UMLS, a large biomedical database.\n",
    "print(a.ents)\n",
    "\n",
    "\n",
    "#>>> (Myeloid derived suppressor cells,\n",
    "#     MDSC,\n",
    "#     immature,\n",
    "#     myeloid cells,\n",
    "#     immunosuppressive activity,\n",
    "#     accumulate,\n",
    "#     tumor-bearing mice,\n",
    "#     humans,\n",
    "#     cancer,\n",
    "#     hepatocellular carcinoma,\n",
    "#     HCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ac3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also visualise dependency parses\n",
    "# (This renders automatically inside a jupyter notebook!):\n",
    "from spacy import displacy\n",
    "# displacy.render(next(doc2.sents), style='dep', jupyter=True)\n",
    "displacy.render(a, style='dep', jupyter=True)\n",
    "\n",
    "# See below for the generated SVG.\n",
    "# Zoom your browser in a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc01426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1887e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd250a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa559c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d1a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582371e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15373c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be52c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2734ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba911c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7371bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8562bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71c0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
