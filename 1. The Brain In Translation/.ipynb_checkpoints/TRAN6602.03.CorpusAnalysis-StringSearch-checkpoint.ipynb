{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d386e32e",
   "metadata": {},
   "source": [
    "#### (4月12日) Corpus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99017208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Project-specific functions\n",
    "from functions import collapse, preprocess_gen, initialize_results_df, unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle\n",
    "corpus_new = pd.read_pickle('savefiles/corpusfull_20220410.pkl')\n",
    "toks_df = pd.read_pickle('savefiles/toksdf_20220413.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37e6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts each doc from list of paras to one long string\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = collapse(corpus_new.loc[i, \"Text\"])\n",
    "\n",
    "# Preprocess each doc before Spacy modeling\n",
    "for i in range(0,20):\n",
    "    corpus_new.loc[i, \"Text\"] = preprocess_gen(corpus_new.loc[i, \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeefcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row indices of docs in respective corpora\n",
    "jpen_i = [0,  1,  5, 10, 11, 12, 13, 14, 17, 19]\n",
    "enen_i = [2,  3,  4,  6,  7,  8,  9, 15, 16, 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c4612",
   "metadata": {},
   "source": [
    "### (4月26日) Token results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "087005ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>JP-EN Mean Count</th>\n",
       "      <th>JP-EN Mean Freq</th>\n",
       "      <th>EN-EN Mean Count</th>\n",
       "      <th>EN-EN Mean Freq</th>\n",
       "      <th>P (count)</th>\n",
       "      <th>P (freq)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>active</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.079231</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.425237</td>\n",
       "      <td>0.039044</td>\n",
       "      <td>0.028967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token  JP-EN Mean Count  JP-EN Mean Freq  EN-EN Mean Count  \\\n",
       "723  active               0.5         0.079231               2.8   \n",
       "\n",
       "     EN-EN Mean Freq  P (count)  P (freq)  \n",
       "723         0.425237   0.039044  0.028967  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter token (lemma) as string to compare between JP-EN/EN-EN\n",
    "\n",
    "toks_df[toks_df['Token'] == 'active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62065b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92036ceb",
   "metadata": {},
   "source": [
    "### (4月23日) Search for tokens/strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39fabb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a58fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each text as scispaCy doc \n",
    "corpus_new['spacy_docs'] = [nlp(text) for text in corpus_new['Text']]\n",
    "\n",
    "# Get each text as list of scispaCy sentences\n",
    "# sent_list = []\n",
    "# for i in range(0,20):\n",
    "#     s = list([x for x in corpus_new.spacy_docs[i].sents])\n",
    "#     sent_list.append(s)\n",
    "# corpus_new['spacy_sents'] = pd.Series(sent_list)\n",
    "# print([x for x in corpus_new.spacy_docs[i].sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a849582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 match(es) in Tamura [doc 0]\n",
      "-  The posterior cingulate cortex (PCC) was also activated by risk-taking vs. safe actions.\n",
      "-  These reports are consistent with the present finding that the observation of risk-taking actions (compared to safe ones) activated the PCC.\n",
      "-  For example, the precuneus is activated during ‘forgivability’ judgments in social scenarios and in the attribution of emotions to the self and others.\n",
      "\n",
      "0 match(es) in Watanabe [doc 1]\n",
      "\n",
      "14 match(es) in Ohta [doc 5]\n",
      "-  Lastly, we established that nonlinguistic order-related and error-related factors significantly activated the right (R.) lateral premotor cortex and R. F3op/F3t, respectively.\n",
      "-  Other significantly activated regions were the right (R.) F3op/F3t, R. LPMC, anterior cingulate cortex (ACC), and R. SMG.\n",
      "-  Seed masks were set in the pair of L. F3op/F3t and L. SMG, both of which were significantly activated in Nested’(L)>Simple’(S).\n",
      "-  Other significantly activated regions were L. LPMC/F3op and ACC under the sentence conditions, as well as R. SMG under the string conditions (Table 4).\n",
      "-  Lastly, we established that nonlinguistic order-related and error-related factors significantly activated mostly right frontal regions.\n",
      "-  A previous fMRI study involving the implicit learning of an artificial regular grammar has reported that the “ungrammatical – grammatical” contrast for symbol sequences activated L. F3op/F3t, suggesting that such activation was due to artificial syntactic violations among any error-related factors.\n",
      "-  Moreover, our previous studies revealed that the functional connectivity between L. F3t/F3O (pars orbitalis) and L. AG/SMG was selectively enhanced during sentence processing and that L. AG/SMG was also activated during the identification of correct past-tense forms of verbs, probably reflecting an integration of syntactic and vocabulary knowledge.\n",
      "-  In [Nonmatching – Matching], R. F3op/F3t was consistently activated under both sentence and string conditions (Figure 5A and 5B), whereas L. LPMC/F3op, ACC, or R. SMG were activated under either condition.\n",
      "-  In [Nonmatching – Matching], R. F3op/F3t was consistently activated under both sentence and string conditions (Figure 5A and 5B), whereas L. LPMC/F3op, ACC, or R. SMG were activated under either condition.\n",
      "-  These four regions were also activated in Nested’>Simple’, and in Long>Short while combining Nested’ and Simple’; the ACC and R. SMG were activated in Nested”>Reverse” as well.\n",
      "-  These four regions were also activated in Nested’>Simple’, and in Long>Short while combining Nested’ and Simple’; the ACC and R. SMG were activated in Nested”>Reverse” as well.\n",
      "-  In contrast to these factors that activated mostly right and medial regions, it is noteworthy that the syntactic factors clearly activated the left frontal and parietal regions.\n",
      "-  In contrast to these factors that activated mostly right and medial regions, it is noteworthy that the syntactic factors clearly activated the left frontal and parietal regions.\n",
      "-  Any factors associated with matching orders and symbol orders might influence activation in the language areas, but we clearly showed that R. LPMC was activated in Reverse” (Figure 5C) for the effect of memory span related to matching orders.\n",
      "\n",
      "15 match(es) in Minamoto [doc 10]\n",
      "-  Some studies have localized the neural correlates of frustration, which can be a cause of aggressive behavior as proposed by Dollard et al.. For example, a violation of reward expectation activates the ventrolateral prefrontal cortex (VLPFC) and the insula while social frustration can also activate the VLPFC as well as the cingulate cortex.\n",
      "-  Some studies have localized the neural correlates of frustration, which can be a cause of aggressive behavior as proposed by Dollard et al.. For example, a violation of reward expectation activates the ventrolateral prefrontal cortex (VLPFC) and the insula while social frustration can also activate the VLPFC as well as the cingulate cortex.\n",
      "-  Higher order cognitive operations might be recruited in this situation, activating the dorsolateral prefrontal cortex (DLPFC) and the posterior parietal cortex.\n",
      "-  In addition, we localized those brain regions that activate differently between the two groups across the two frustrating conditions.\n",
      "-  We first examined differences in brain activation between the frustration conditions (the ego-blocking and superego-blocking conditions) and control condition (general knowledge condition), as this allowed us to evaluate whether the PF study activated the brain regions related to frustration.\n",
      "-  We extracted the percent signal change of the activated cluster and ran two-way mixed ANOVA for comparison.\n",
      "-  One structure we did not observe to be activated was the anterior cingulate cortex (ACC), which disagrees with other studies.\n",
      "-  Similarly, the PF study does not contain threatening stimuli such as a fearful face, which could activate the amygdala.\n",
      "-  Therefore, the ego-blocking situation seems not to activate automatic emotional processing; rather it activates neural networks related to mentalizing and empathy.\n",
      "-  Therefore, the ego-blocking situation seems not to activate automatic emotional processing; rather it activates neural networks related to mentalizing and empathy.\n",
      "-  Differences were further seen between extrapunitive individuals and intropunitive individuals in the ego-blocking condition, as distinct parts of the prefrontal cortex were activated.\n",
      "-  Therefore, taken together, in a situation where other people block a goal or desire, individuals with extrapunitive tendencies can activate an affective component while those with intropunitive tendencies drive a cognitive component of the general aggression model.\n",
      "-  Both groups then aim to resolve a frustrating situation that potentially harms self-esteem in a manner that activates the fronto-parietal network.\n",
      "-  Dopamine levels in the DLPFC may explain why different parts of the prefrontal cortex were activated between the extrapunitive and intropunitive groups in the ego-blocking condition but not in the super-ego blocking condition.\n",
      "-  Beta weight value of each brain region activated in the ego-blocking condition in comparison to the control condition.\n",
      "\n",
      "0 match(es) in Itahashi [doc 11]\n",
      "\n",
      "6 match(es) in Yomogida [doc 12]\n",
      "-  The results indicate that, whereas implicit ES activated the lateral prefrontal cortex and medial/lateral parietal cortex, explicit ES activated the medial prefrontal cortex, posterior cingulate cortex, and medial/lateral temporal cortex.\n",
      "-  The results indicate that, whereas implicit ES activated the lateral prefrontal cortex and medial/lateral parietal cortex, explicit ES activated the medial prefrontal cortex, posterior cingulate cortex, and medial/lateral temporal cortex.\n",
      "-  The explicit and implicit processes activated different subregions within the lateral PPC.\n",
      "-  This region was activated more when subjects believed they were playing games with a human opponent compared with a computer program.\n",
      "-  Similarly, this region is known to be activated more in children than in adults when understanding others' minds, reflecting a greater explicit process in children.\n",
      "-  This anterior part was activated only when subjects were explicitly instructed to process such contextual information.\n",
      "\n",
      "5 match(es) in Murakami [doc 13]\n",
      "-  For example, the dorsolateral prefrontal cortex (DLPFC) is activated during working memory tasks that are frequently used to induce mental stress [32,33], and that such activation becomes more pronounced as task difficulty increases.\n",
      "-  The suppression strategy in our study activated the ventrolateral prefrontal cortex (VLPFC), which is in line with evidence that the VLPFC plays a primary role in suppressing emotion [27,29,30].\n",
      "-  Additionally, the dACC was activated during the Observe condition.\n",
      "-  Reportedly, the DLPFC is activated during the tasks requiring cognitive effort which leads to enhancement of sympathetic nervous activity.\n",
      "-  Moreover, the mindful coping strategy seemed to activate the parasympathetic nervous system which is known to be modulated by MPFC activity.\n",
      "\n",
      "26 match(es) in Higashiyama [doc 14]\n",
      "-  Three brain regions were activated during both the typing and the writing tasks: the left superior parietal lobule, the left supramarginal gyrus, and the left premotor cortex close to Exner’s area.\n",
      "-  Purcell et al. used fMRI to investigate the neural basis of spelling via keyboard typing and found that typed spelling activated a predominantly left hemisphere network including the inferior frontal gyrus (IFG), middle frontal gyrus (MFG)/superior frontal gyrus (SFG), supramarginal gyrus (SMG), SPL, and fusiform gyrus, in common with the results from lesion studies in agraphia and functional imaging studies of writing.\n",
      "-  Several activated areas were present including the bilateral inferior occipital gyri extending to the left inferior temporal cortex, the left frontoparietal areas such as the SPL, the posterior part of the left MFG, the upper and lower parts of the left pre-central gyrus, and the left IFG, corresponding to Broca’s area.\n",
      "-  Large extents of the bilateral frontoparietal regions were significantly activated.\n",
      "-  Activated regions included the bilateral pre-central gyrus, the left SPL, and the right middle cingulate gyrus.\n",
      "-  The left cerebellum, including the left vermis, and the left hemisphere were also significantly activated.\n",
      "-  The bilateral cerebellum, the posterior part of the right SFG, and the right thalamus were also activated.\n",
      "-  The results of the “writing > typing” contrast showed no activated brain regions.\n",
      "-  Three left frontoparietal regions were significantly activated: the left anterior SPL, the posterior part of the left MFG/SFG, and the left SMG.\n",
      "-  The posterior parts of the MFG activated in both conjunction contrasts correspond to Exner’s area.\n",
      "-  The results of the (writing > writing movement) > (typing > typing movement) contrast showed no activated brain regions.\n",
      "-  Our fMRI study revealed three brain regions activated during both tasks: the left anterior SPL, the left SMG, and the posterior end of the left MFG/SFG.\n",
      "-  These brain regions, known as the “writing centers” from numerous lesion studies and neuroimaging studies, were activated in both the typewriting and the writing task.\n",
      "-  In addition, our data suggest the same brain region, the left SPL, was also activated in the typewriting task.\n",
      "-  These results indicated that these IPS regions were activated to a greater degree in the typing task than in the writing task (Fig 7).\n",
      "-  A meta-analysis of fMRI studies for English written word production that contained a typewriting task indicated that the posterior part of the IPS cluster was activated during central spelling processes, and this is very close to our activated area for typewriting (MNI peak: -30, -60, 46).\n",
      "-  A meta-analysis of fMRI studies for English written word production that contained a typewriting task indicated that the posterior part of the IPS cluster was activated during central spelling processes, and this is very close to our activated area for typewriting (MNI peak: -30, -60, 46).\n",
      "-  Overlap of the MFG activated regions obtained from the conjunction analysis of typing (red) and writing (blue).\n",
      "-  Grefkes et al. proposed that the medial IPS was also crucial for transforming visual coordinates into motor programs and was activated bilaterally in the online control of goal-directed precision movements [32, 33].\n",
      "-  It is interesting that only the left IPS was activated in our study.\n",
      "-  A recent functional imaging study demonstrated that the bilateral IPS was significantly activated during mental rotation tasks known to be associated with visual representation.\n",
      "-  It is noteworthy that a direct comparison between the two left MFG/SFG activated clusters obtained from typing and writing conjunctions revealed a small gap (Fig 7).\n",
      "-  Moreover, Simon et al. suggested that the region of the dorsal premotor area activated for motor preparation is located caudally and that activated for spatial attention and memory is located at a more rostral site.\n",
      "-  Moreover, Simon et al. suggested that the region of the dorsal premotor area activated for motor preparation is located caudally and that activated for spatial attention and memory is located at a more rostral site.\n",
      "-  The dystypia case reported by Ryu et al. had lesions in the bilateral border-zone regions, predominantly the left dorsal frontal area, that were relatively close to our left MFG/SFG activated area.\n",
      "-  The results of the writing > typing contrast showed no activated brain regions.\n",
      "\n",
      "1 match(es) in Nakai [doc 17]\n",
      "-  Among those activated regions, left-lateralized activation in the IFG and LPMC may reflect recursive computation of sequential symbols common to language and mathematics.\n",
      "\n",
      "6 match(es) in Nakata [doc 19]\n",
      "-  This is often explained by the blood steal phenomenon, which occurs due a decrease in blood flow (i.e. Negative response) in regions that are adjacent to activated regions with increased blood flow (i.e. Positive response) and supplied by a common artery.\n",
      "-  Group activation map showing (A) activated (Positive BOLD) and (B) deactivated (Negative BOLD) brain regions in the RH condition.\n",
      "-  Group activation map showing (A) activated (Positive BOLD) and (B) deactivated (Negative BOLD) brain regions in the LH condition.\n",
      "-  Group activation map showing (A) activated (Positive BOLD) and (B) deactivated (Negative BOLD) brain regions in the RF condition.\n",
      "-  Group activation map showing (A) activated (Positive BOLD) and (B) deactivated (Negative BOLD) brain regions in the LF condition.\n",
      "-  Activated regions in the Positive BOLD analysis are listed in S2 Table.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of matching sentences (JP-EN)\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "for n in jpen_i:\n",
    "    doc = corpus_new['spacy_docs'][n]\n",
    "\n",
    "    pattern = [{'LEMMA': 'activate'}]\n",
    "\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"SCREENER\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Iterate over the matches\n",
    "    print(f'{len(matches)} match(es) in {corpus_new[\"Author\"][n]} [doc {n}]')\n",
    "    for match_id, start, end in matches:\n",
    "        # Get the matched span\n",
    "        matched_span = doc[start:end]\n",
    "        print('- ', matched_span.sent.text)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2379260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 match(es) in Sobhani [doc 2]\n",
      "-  Each of these study components is described in detail below.\n",
      "-  Participants were also asked to identify each of the targets and recount details of the target’s story as a way of ensuring that all the targets were equally and accurately remembered.\n",
      "-  ROIs were hand-drawn for each subject based upon anatomical boundaries detailed in (See Figure 2 for locations; see Table S1 for boundaries).\n",
      "\n",
      "6 match(es) in Majdandžić [doc 3]\n",
      "-  In order to examine the effects of our manipulation in more detail, we presented the participants with a questionnaire after the scanning session in which we explored their feelings towards the fictitious persons.\n",
      "-  Planned comparisons and post-hoc t-tests were applied to assess specific effects in more detail.\n",
      "-  The comparison between dilemma decisions involving Humanized versus Neutral persons (contrast Humanized > Neutral Dilemmas) revealed the following significant clusters (see Table 1, Figure 4, for details).\n",
      "-  The PPI analysis testing for regions that showed increased coupling with aMCC/RCZ during Humanized compared to Neutral dilemmas identified a set of regions that involved among others bilateral (mainly left) precuneus extending into the cuneus, extensive clusters bilaterally covering the anterior insula, extending into adjacent IFG (pars triangularis and orbitalis) and on the left side into the middle orbital gyrus, and a cluster in the left angular gyrus/TPJ (see Table 2 and Figure 5 for details).\n",
      "-  In the following sections, we discuss our findings in detail and elaborate on their implications for understanding the role of humanized perception in decision making and prosocial behavior.\n",
      "-  In the following paragraphs we discuss the functions of the areas recruited by our manipulation in more detail and draw inferences on the nature of the humanization effect.\n",
      "\n",
      "0 match(es) in Dixon [doc 4]\n",
      "\n",
      "1 match(es) in Deeley [doc 6]\n",
      "-  Psychophysiological interaction connectivity analysis showed reduced connectivity between SMA and other brain regions following suggested involuntary movement relative to voluntary movement (hyp-vol > hyp-involA) as detailed in Table 4.\n",
      "\n",
      "2 match(es) in Pawliczek [doc 7]\n",
      "-  To assess aggressive tendencies in more detail, participants filled in the Psychopathic Personality Inventory Revised (PPI-R) [36,37], the Life History of Aggression scale (LHA) and the Freiburger Aggression Inventory (FAI).\n",
      "-  The main effect of condition (solvable vs. unsolvable anagrams) revealed activation in the cingulate cortex, the bilateral superior and left middle frontal cortex, the bilateral angular gyrus and the superior parietal regions (for more details see Table S1).\n",
      "\n",
      "3 match(es) in Jansma [doc 8]\n",
      "-   (See 22 for details of the technique.) This device enables anatomical landmarks on the skin of the participants to be co-registered with the same landmarks on a skin rendering based on their MRI scans.\n",
      "-  A Neopulse TMS device (Neotonus Inc, Atlanta) with an iron core coil was used (see Epstein et al, 2002 for details).\n",
      "-  The pulse intensity was 110% of the individual motor threshold, which was defined before the experiment as the minimum intensity that would induce a visible muscle twitch in the contra lateral hand on at least five out of ten occasions (see 23 for details).. In order for us to control for nonspecific rTMS effects such as tactile and auditory sensations, participants also performed a session with a sham coil.\n",
      "\n",
      "5 match(es) in Lidzba [doc 9]\n",
      "-  The theoretical focus of the EFT lies on the assumption that local details have to be “disembedded” from the global gestalt of the stimulus.\n",
      "-  Subjects were compensated for their participation according to the time they spent on the study.. The task is described in detail in.\n",
      "-  In the search condition, 50% of the pairs were identical, while in the other trials a detail was missing in one of the figures (Figure 1, left).\n",
      "-  Participants were told to press a button whenever the two figures were not the same, i.e., when a detail was missing (search condition) or when the orientations were different (control condition).\n",
      "-  We assumed that the search condition differentially engages visuospatial working memory (keeping the \"correct\" pattern online), top-down guided visual attention shifts (systematically searching the patterns), saccades (between the two versions and within the searched pattern), pattern recognition (comparing the details of the searched pattern), and inhibition (e.g., of already searched parts of the pattern).\n",
      "\n",
      "1 match(es) in Neale [doc 15]\n",
      "-  These networks and the differences between them are discussed in detail, as well as implications for future research in middle aged cohorts.\n",
      "\n",
      "0 match(es) in Kim [doc 16]\n",
      "\n",
      "1 match(es) in Himmelstein [doc 18]\n",
      "-  In the following paragraphs, we will examine each of these variables in greater detail and discuss their significance to the field of autobiographical memory and linguistic analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of matching sentences (EN-EN)\n",
    "\n",
    "for n in enen_i:\n",
    "    doc = corpus_new['spacy_docs'][n]\n",
    "\n",
    "    pattern = [{'LEMMA': 'detail'}]\n",
    "\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"SCREENER\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Iterate over the matches\n",
    "    print(f'{len(matches)} match(es) in {corpus_new[\"Author\"][n]} [doc {n}]')\n",
    "    for match_id, start, end in matches:\n",
    "        # Get the matched span\n",
    "        matched_span = doc[start:end]\n",
    "        print('- ', matched_span.sent.text)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3011ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e15cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "matches = []\n",
    "\n",
    "for i, sent in enumerate(corpus_new.spacy_sents[0]):\n",
    "    if 'report' in sent.lemma_:\n",
    "        #words = re.findall('report', sent.text)\n",
    "        matches.append(tuple((i, sent.text)))\n",
    "    \n",
    "matches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b03cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f320b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435ebe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7289758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tok(doc):\n",
    "    \n",
    "    # Collect lemmas not tagged by spaCy as 1. punctuation, 2. digits, 3. URLs, or 4. stop words\n",
    "    tokens = [tok.lemma_ for tok in doc if not (tok.is_punct | tok.is_digit | tok.like_url | tok.is_stop)]\n",
    "    \n",
    "    # Remove any tokens containing mid-string digits (e.g. \"P5-a\") or punc ('t(are')\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\d\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\(\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\)\", tok)]\n",
    "    \n",
    "    # (4.13) Break apart hyphen- or slash-separated compounds\n",
    "    seps = ['-', '–', '―',\n",
    "            ';', ':',\n",
    "            '\\]', '\\[', \n",
    "            '’', '”', \n",
    "            '>', '<', '/']\n",
    "    for sep in seps:\n",
    "        new_toks = []\n",
    "        for tok in tokens:\n",
    "            new_toks += tok.split(sep)\n",
    "        tokens = new_toks\n",
    "    \n",
    "    # (4.13) Remove remaining abbreviations\n",
    "    tokens = [tok for tok in tokens if not re.search(\"[a-zA-Z]\\.[a-zA-Z]\\.\", tok)]\n",
    "    tokens = [tok for tok in tokens if not re.search(\"\\+\", tok)]\n",
    "    \n",
    "    # Remove punc and small words (e.g. 'a', 'P', 'mm')\n",
    "    punc_to_skip = set(['±', '=', '>', '<'])\n",
    "    tokens = [tok for tok in tokens if tok not in punc_to_skip]     # can skip?\n",
    "    tokens = [tok for tok in tokens if len(tok) > 3]    \n",
    "       \n",
    "    # Unify to lowercase (to simplify matching)\n",
    "    tokens = [tok.lower() for tok in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tokens_unique_to_one_doc(i):\n",
    "    \n",
    "    other_docs = list(range(0,20))\n",
    "    other_docs.remove(i)\n",
    "    \n",
    "    # Doc in question\n",
    "    text_i = corpus_new.loc[i, \"Text\"]\n",
    "    doc_i = nlp(text_i)\n",
    "    tokens_i = unique(preprocess_tok(doc_i))\n",
    "    \n",
    "    # Iterate thru all 19 other docs\n",
    "    for j in other_docs:\n",
    "        text_j = corpus_new.loc[j, \"Text\"]\n",
    "        doc_j = nlp(text_j)\n",
    "        tokens_j = set(unique(preprocess_tok(doc_j)))\n",
    "        \n",
    "        for tok in tokens_i:\n",
    "            if tok in tokens_j:\n",
    "                tokens_i.remove(tok)\n",
    "    \n",
    "    return tokens_i            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance of preprocessing function\n",
    "toks_unique = find_tokens_unique_to_one_doc(5)\n",
    "toks_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d817c",
   "metadata": {},
   "source": [
    "### Word-level analysis (4/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69a232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmas more common in JP-EN than EN-EN\n",
    "toks_jp = toks_df[(toks_df[\"JP-EN Mean Freq\"] > toks_df[\"EN-EN Mean Freq\"]) &\n",
    "                 (toks_df[\"JP-EN Mean Count\"] >= 1)]\n",
    "toks_jp.sort_values(\"P (freq)\", inplace=True)\n",
    "results_tokjp = toks_jp[[\"Token\", \"JP-EN Mean Freq\",\n",
    "                         \"EN-EN Mean Freq\", \"P (freq)\"]].reset_index(drop=True)\n",
    "\n",
    "results_tokjp.head(60)\n",
    "#results_tokjp[:40].to_csv(\"savefiles/results_tokjp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmas less common in JP-EN than EN-EN\n",
    "toks_en = toks_df[(toks_df[\"JP-EN Mean Freq\"] < toks_df[\"EN-EN Mean Freq\"]) &\n",
    "                 (toks_df[\"EN-EN Mean Count\"] >= 1)]\n",
    "toks_en.sort_values(\"P (freq)\", inplace=True)\n",
    "results_token = toks_en[[\"Token\", \"JP-EN Mean Freq\",\n",
    "                         \"EN-EN Mean Freq\", \"P (freq)\"]].reset_index(drop=True)\n",
    "\n",
    "results_token.head(60)\n",
    "#results_token[:40].to_csv(\"savefiles/results_token.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means('n_think')\n",
    "compare_means('n_consider')\n",
    "compare_means('n_think_adj')\n",
    "compare_means('n_consider_adj')\n",
    "compare_means('n_report')\n",
    "compare_means('n_report_adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf87b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    results_df.loc[i, 'Combined'] = results_df.loc[i, 'n_think'] + results_df.loc[i, 'n_consider']\n",
    "    results_df.loc[i, 'Combined_adj'] = results_df.loc[i, 'Combined'] / results_df.loc[i, 'Word Count']\n",
    "    \n",
    "compare_means('Combined')\n",
    "compare_means('Combined_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20992527",
   "metadata": {},
   "source": [
    "### For 2,3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = initialize_results_df()\n",
    "cols = []\n",
    "\n",
    "for lexeme in [\"in this study\", \"therefore\", \"in addition\", \"bold response\"]:\n",
    "    \n",
    "    new_name_n = \"n_\" + str(lexeme.replace(\" \", \"\"))\n",
    "    new_name_adj = str(new_name_n) + \"_adj\"\n",
    "    cols.append(new_name_n)\n",
    "    cols.append(new_name_adj)\n",
    "\n",
    "    for i in range(0,20):\n",
    "        text = corpus_new.loc[i, \"Text\"].lower()\n",
    "        ct = text.count(lexeme)\n",
    "        # Put in results_df\n",
    "        results_df.loc[i, new_name_n] = ct\n",
    "        results_df.loc[i, new_name_adj] = (ct / results_df.loc[i, 'Word Count']) #* np.mean(results_df['Word Count'])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad86023",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    compare_means(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7bd13a",
   "metadata": {},
   "source": [
    "### Statistical testing\n",
    "#### 1. Type/token ratio (lexical diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(doc):\n",
    "    \n",
    "    token_list = preprocess_tok(doc)\n",
    "    n_type = len(unique(token_list))\n",
    "    n_token = len(token_list)\n",
    "    ttr = n_type/n_token\n",
    "    \n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4497a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(var):\n",
    "    \n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    jp_stats = list(results_df[results_df['Group'] == 'JP-EN'].loc[:, var])\n",
    "    en_stats = list(results_df[results_df['Group'] == 'EN-EN'].loc[:, var])\n",
    "    P = ttest_ind(jp_stats, en_stats).pvalue\n",
    "    \n",
    "    print(f'Mean {var}, JP-EN:  {np.mean(jp_stats)}')\n",
    "    print(f'Mean {var}, EN-EN:  {np.mean(en_stats)}')\n",
    "    print(f'Sig. (unpaired t-test): {P}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate raw type/token ratio (lemmatized)\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Run scispaCy model\n",
    "    doc = nlp(text)\n",
    "    # Preprocess\n",
    "    ttr = type_token_ratio(doc)\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Type/Token'] = ttr\n",
    "\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted type/token ratio (lemmatized) divided by word count\n",
    "\n",
    "for i in range(0,20):\n",
    "    # Pull text from df\n",
    "    text = corpus_new.loc[i, \"Text\"]\n",
    "    # Split by word (\" \" for simplicity)\n",
    "    word_ct = len(text.split(' '))\n",
    "    # Put in results_df\n",
    "    results_df.loc[i, 'Word Count'] = word_ct\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by mean word count of all documents\n",
    "results_df['TTR_adj'] = (results_df['Type/Token'] / results_df['Word Count']) * np.mean(results_df['Word Count'])\n",
    "    \n",
    "results_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean stats between JP-EN and EN-EN corpora\n",
    "\n",
    "compare_means('Type/Token')\n",
    "compare_means('Word Count')\n",
    "compare_means('TTR_adj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9949952",
   "metadata": {},
   "source": [
    "Comments (4/10): H1 seems to be rejected. fMRI studies authored by Japanese scientists are just as lexically sophisticated as comparable docs authored by Anglophone counterparts. Perhaps this is a good thing: i.e., any differences discovered later are a product of linguistic features, rather than scientific knowledge/ignorance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4959e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610f4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
