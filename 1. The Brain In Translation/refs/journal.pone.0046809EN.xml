<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><issn pub-type="epub">1932-6203</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PONE-D-12-12572</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0046809</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Cognitive neuroscience</subject>
              <subj-group>
                <subject>Cognition</subject>
                <subject>Motor reactions</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Neuroimaging</subject>
              <subj-group>
                <subject>fMRI</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Motor systems</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Medicine</subject>
          <subj-group>
            <subject>Mental health</subject>
            <subj-group>
              <subject>Psychology</subject>
              <subj-group>
                <subject>Human relations</subject>
                <subject>Social psychology</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Neurology</subject>
            <subj-group>
              <subject>Neuroimaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Human relations</subject>
              <subject>Social psychology</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Sociology</subject>
            <subj-group>
              <subject>Social discrimination</subject>
              <subj-group>
                <subject>Racial discrimination</subject>
                <subject>Social prejudice</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Religion</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Mental Health</subject>
          <subject>Neuroscience</subject>
          <subject>Neurological Disorders</subject>
        </subj-group>
      </article-categories><title-group><article-title>Interpersonal Liking Modulates Motor-Related Neural Regions</article-title><alt-title alt-title-type="running-head">Liking Modulates Motor-Related Regions</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Sobhani</surname>
            <given-names>Mona</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Fox</surname>
            <given-names>Glenn R.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kaplan</surname>
            <given-names>Jonas</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Aziz-Zadeh</surname>
            <given-names>Lisa</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
        <label>1</label>
        <addr-line>Neuroscience Graduate Program, University of Southern California, Los Angeles, California, United States of America</addr-line>
      </aff><aff id="aff2">
        <label>2</label>
        <addr-line>Brain and Creativity Institute Los Angeles, Los Angeles, California, United States of America</addr-line>
      </aff><aff id="aff3">
        <label>3</label>
        <addr-line>Department of Psychology, University of Southern California, Los Angeles, California, United States of America</addr-line>
      </aff><aff id="aff4">
        <label>4</label>
        <addr-line>Division of Occupational Science and Occupational Therapy, University of Southern California, Los Angeles, California, United States of America</addr-line>
      </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Brass</surname>
            <given-names>Marcel</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">
        <addr-line>Ghent University, Belgium</addr-line>
      </aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">mssobhani@gmail.com</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: MS GRF LAZ. Performed the experiments: MS GRF. Analyzed the data: MS JK. Wrote the paper: MS.</p>
        </fn>
      </author-notes><pub-date pub-type="collection">
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>5</day>
        <month>10</month>
        <year>2012</year>
      </pub-date><volume>7</volume><issue>10</issue><elocation-id>e46809</elocation-id><history>
        <date date-type="received">
          <day>24</day>
          <month>4</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>7</day>
          <month>9</month>
          <year>2012</year>
        </date>
      </history><permissions>
        
        <copyright-holder>Sobhani et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions><abstract>
        <p>Observing someone perform an action engages brain regions involved in motor planning, such as the inferior frontal, premotor, and inferior parietal cortices. Recent research suggests that during action observation, activity in these neural regions can be modulated by membership in an ethnic group defined by physical differences. In this study we expanded upon previous research by matching physical similarity of two different social groups and investigating whether likability of an outgroup member modulates activity in neural regions involved in action observation. Seventeen Jewish subjects were familiarized with biographies of eight individuals, half of the individuals belonged to Neo-Nazi groups (dislikable) and half of which did not (likable). All subjects and actors in the stimuli were Caucasian and physically similar. The subjects then viewed videos of actors portraying the characters performing simple motor actions (e.g. grasping a water bottle and raising it to the lips), while undergoing fMRI. Using multivariate pattern analysis (MVPA), we found that a classifier trained on brain activation patterns successfully discriminated between the likable and dislikable action observation conditions within the right ventral premotor cortex. These data indicate that the spatial pattern of activity in action observation related neural regions is modulated by likability even when watching a simple action such as reaching for a cup. These findings lend further support for the notion that social factors such as interpersonal liking modulate perceptual processing in motor-related cortices.</p>
      </abstract><funding-group>
        <funding-statement>This research was supported by the Brain and Creativity Institute and the Division of Occupational Science and Occupational Therapy at the University of Southern California. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group><counts>
        <page-count count="9"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Observing goal-directed actions recruits a concert of neural resources. When we observe another person’s goal-directed motor actions, a rich array of information is read into the brain, giving us the necessary input to understand aspects of the observed action, including the possible outcomes of the action to the intent behind the action. Being able to gauge the intent of others’ actions is a vital skill that is highly relevant to the survival of the observer. In its most basic form, observing another person performing an action reveals a network of neural regions, including the inferior frontal gyrus (IFG), ventral premotor cortex (vPMC), and inferior parietal lobule (IPL) <xref ref-type="bibr" rid="pone.0046809-Rizzolatti1">[1]</xref>. Specific motor-related neurons in the macaque monkey brain have been found to be active both when the monkey performs an action and when it observes the same or a similar action performed by another individual <xref ref-type="bibr" rid="pone.0046809-Rizzolatti2">[2]</xref>. It has been suggested that these neurons are “mirroring” the actions that they observe, and that this may be a mechanism by which the monkey can simulate and understand these observed actions <xref ref-type="bibr" rid="pone.0046809-Gallese1">[3]</xref>. Neural regions exhibiting these properties in the macaque brain include the (F5) vPMC and the IPL. Functional neuroimaging studies in humans have provided a means for examining neural processing during action observation, revealing the recruitment of homologous regions to those found in the monkey brain (Gallese, Keysers, &amp; Rizzolatti, 2004; Rizzolatti &amp; Craighero, 2004). Evidence suggests that activation of human motor-related brain regions during the observation of actions is similar to activation when an action is performed. Observing a wide array of actions, ranging from object directed actions to communicative gestures <xref ref-type="bibr" rid="pone.0046809-Grafton1">[4]</xref>–<xref ref-type="bibr" rid="pone.0046809-Liew1">[6]</xref> engages this fronto-parietal network.</p>
      <p>Other investigations have revealed how these regions may be modulated by higher-level and socially relevant factors. For instance, emerging evidence suggests that these brain regions may be modulated by factors such as physical differences <xref ref-type="bibr" rid="pone.0046809-Buccino1">[7]</xref>–<xref ref-type="bibr" rid="pone.0046809-Liew2">[9]</xref>, and culture <xref ref-type="bibr" rid="pone.0046809-MolnarSzakacs1">[5]</xref>, <xref ref-type="bibr" rid="pone.0046809-Liew1">[6]</xref>. In parallel, social group membership has been shown to modulate behavior <xref ref-type="bibr" rid="pone.0046809-Weisbuch1">[10]</xref> and physiological responses <xref ref-type="bibr" rid="pone.0046809-Brown1">[11]</xref>, leading into investigations of neural correlates of these observations. Findings from these investigations have revealed the effect of aspects of social group membership on various sensory-motor and cognitive processes. For example, Hart and colleagues (2000) demonstrated that both Black and White individuals displayed increased amygdala activation to out-group faces <xref ref-type="bibr" rid="pone.0046809-Hart1">[12]</xref>. Another study revealed that Caucasian and Chinese individuals displayed decreased neural activation in the anterior cingulate cortex and inferior frontal/insula in response to viewing the application of painful stimulation to out-group members <xref ref-type="bibr" rid="pone.0046809-Xu1">[13]</xref>. Thus, it appears that neural processing differs for in-groups and out-groups across various types of stimuli, particularly when group membership is defined by race.</p>
      <p>It is unknown, however, how social group-based interpersonal liking, can affect sensory-motor neural regions, such as those involved in action observation. Generally, it has been demonstrated that action observation related neural regions are more active in response to stimuli of the self as opposed to that of others <xref ref-type="bibr" rid="pone.0046809-Uddin1">[14]</xref>, <xref ref-type="bibr" rid="pone.0046809-Kaplan1">[15]</xref>, as well as for people who are more physically similar to oneself <xref ref-type="bibr" rid="pone.0046809-MolnarSzakacs1">[5]</xref>. Based on these findings and the notion that members of one’s social group can be viewed as an extension of oneself <xref ref-type="bibr" rid="pone.0046809-Turner1">[16]</xref>, one would expect that action observation related neural regions would be differentially modulated by how we feel about the person we are observing–i.e. how much we like the person or whether or not they like us. Part of this assumption comes from the fact that individuals typically have more empathy for members of their own social group <xref ref-type="bibr" rid="pone.0046809-Hornstein1">[17]</xref>, and that the activity in action observation related neural regions has been shown to be correlated with scores on empathy scales <xref ref-type="bibr" rid="pone.0046809-Kaplan2">[18]</xref>, <xref ref-type="bibr" rid="pone.0046809-Gazzola1">[19]</xref>.</p>
      <p>Thus, given these previous studies, one would expect that group membership would modulate activity in the MNS during action observation. A few studies have been conducted on this topic, with conflicting results. Using corticospinal excitability as a measure of motor system involvement in action observation, Molnar-Szakacs and colleagues (2007) found increased activity when watching members of the same social group performing culture-specific gestures <xref ref-type="bibr" rid="pone.0046809-MolnarSzakacs1">[5]</xref>, while Desy and Theoret (2007) found increased corticospinal excitability for viewing hand actions made by members of another race <xref ref-type="bibr" rid="pone.0046809-Dsy1">[8]</xref>. Using functional magnetic resonance imaging, Losin et al (2011) found enhanced activity in fronto-parietal regions during imitation of meaningless gestures performed by members of one racial outgroup (but not another) <xref ref-type="bibr" rid="pone.0046809-Losin1">[20]</xref>. Another recent study discovered increased activity in the posterior parietal action observation-related region (IPL) and the insula in response to member’s of one’s own race performing communicative hand gestures <xref ref-type="bibr" rid="pone.0046809-Liew1">[6]</xref>. Taken together, these studies indicate that how the brain shapes its response to observed actions is modulated by many factors, including social group membership and physical similarity to self.</p>
      <p>These action observation studies, however, are limited by the fact that they confound social group membership with physical differences between ingroup and outgroup members. That is, in the previous studies, group membership is manifested by physically looking different than the observer’s ingroup, and thus it is unknown whether the observed effects are due to group membership or to physical similarity. Additionally, two of these action observation studies <xref ref-type="bibr" rid="pone.0046809-MolnarSzakacs1">[5]</xref>, <xref ref-type="bibr" rid="pone.0046809-Liew1">[6]</xref> focus on gestures in a role of communication and culture, but do not address the more fundamental question of goal-directed action execution (e.g., raising a cup to the lips) outside of social communication. Lastly, these studies only address perception of group membership, but do not assess interpersonal liking that stems from in-group and out-group interactions. While a recent study exploring empathy for suffering has demonstrated that group membership independent of physical differences can modulate neural responses in neural regions such as the insula and nucleus accumbens <xref ref-type="bibr" rid="pone.0046809-Hein1">[21]</xref>, it is important to determine if the same is true for action observation and corresponding motor related neural regions.</p>
      <p>A further limitation of previous work is that subject’s may feel that negative feelings about the out-group member are socially unacceptable, although they likely possess some unconscious biases <xref ref-type="bibr" rid="pone.0046809-Hewstone1">[22]</xref>. This conflict manifests in the neuroimaging data as a complex time-dependent neural response, whereby neural regions involved in cognitive control of such feelings become active after the response is initially formed by limbic regions. For example, viewing an outgroup member’s face at shorter intervals initially causes increased amygdala activation, however, at longer stimulus presentation intervals, amygdala responses were dampened as frontal areas associated with cognitive control displayed increased activation <xref ref-type="bibr" rid="pone.0046809-Cunningham1">[23]</xref>. To address these limitations in the literature, we use a simple object-directed action observation task and an interaction between two social groups which were: a) physically similar to one another (i.e. all Caucasian), and b) able to openly express dislike for the other group without being hindered by social stigma (i.e. it is not unreasonable for a Jewish individual to express dislike for a social group that openly hates and threatens their own social group, especially one that is commonly openly treated by disdain and contempt from the general population). With this study, we specifically aimed to investigate whether the liking or disliking of individuals which is derived from group membership, modulates regions involved in action observation. To address these goals, we recruited Jewish males and presented to them biographies of eight individuals’ lives, half of whom were presented as dislikable, neo-Nazis and half presented as likable, open-minded individuals. The participants then viewed these likable and dislikable individuals performing simple motor actions (e.g. reaching for, grasping, and bringing a water bottle to the lips) during a functional magnetic resonance imaging scan. Because we expect the overall effect size to be relatively modest (e.g., due to physical similarities between the likable and dislikable individuals) and traditional cognitive subtraction approaches may not be sensitive enough to disambiguate the two conditions, we used multivoxel pattern analysis (MVPA), in addition to typical univariate fMRI analysis, to investigate whether BOLD signal in brain regions previously implicated in action observation processes (inferior frontal cortices, inferior parietal cortices), would be able to distinguish liked persons from disliked persons during an action observation task. Because MVPA considers multiple voxels simultaneously, it is more sensitive than traditional univariate techniques that analyze each voxel separately <xref ref-type="bibr" rid="pone.0046809-Norman1">[24]</xref>, <xref ref-type="bibr" rid="pone.0046809-Pereira1">[25]</xref>. Furthermore, MVPA can reveal when the spatial pattern of activity changes between conditions even when the overall signal level does not differ <xref ref-type="bibr" rid="pone.0046809-Kriegeskorte1">[26]</xref>, <xref ref-type="bibr" rid="pone.0046809-Kriegeskorte2">[27]</xref>. If, as previous studies have suggested, activity in action observation brain regions are modulated by higher level social factors, then we predict that these regions will exhibit different patterns of activity when observing liked and disliked individuals perform actions.</p>
    </sec>
    <sec id="s2" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s2a">
        <title>Participants</title>
        <p>Nineteen healthy, Jewish males (18–30 years of age, mean ± SD = 21.9±3.58) participated in the experiment. Male participants were exclusively included in this study due to the fact that a previous study indicated that neural modulation caused by interpersonal liking may differ between genders, with males displaying more modulation in neural regions associated with shared representations when viewing someone they dislike <xref ref-type="bibr" rid="pone.0046809-Singer1">[28]</xref>. Two participants had to be removed from all analyses due to technical issues; therefore, all discussed results involve the remaining 17 participants. Inclusion criteria included high scores on self-rating measures of Jewish identity using an ethnic identity measure (mean = 42.4, out of 48) <xref ref-type="bibr" rid="pone.0046809-Phinney1">[29]</xref>, as well as a scale created to assess the participant’s self-reported affiliation with the Jewish religion (mean = 39, out of 48). All participants were right-handed, had normal or corrected-to-normal vision, and had no neurological or psychiatric history. Written informed consent was obtained from all participants before inclusion in the study. This study was approved by the University of Southern California’s Institutional Review Board and all research activities were performed in accordance with the Institutional Review Board’s policies.</p>
        <p>General Procedure and Design: All subjects participated in a pre-scan training session where they were familiarized with eight individuals through the use of photos and corresponding fictional biographies. During this session, they completed several behavioral questionnaires on group identity, empathy and how much they liked the individuals they observed. They then participated in a fMRI study where inside the scanner they viewed videos of the eight individuals performing a simple goal-directed action (grasping and bringing a water bottle to the lips) or a video of them sitting behind a table (control condition). Each of these study components is described in detail below.</p>
      </sec>
      <sec id="s2b">
        <title>Pre-Scan Training</title>
        <p>All subjects participated in a training session prior to the scanning session. We modeled our approach after a previous study on social emotions that also consisted of a long and in-depth training session followed by a scanning session <xref ref-type="bibr" rid="pone.0046809-ImmordinoYang1">[30]</xref>. This approach allows participants to build a rich, emotional understanding of the images and stories.</p>
        <p>During this session, participants were familiarized with eight individuals (“targets”) through the use of photos and corresponding fictional biographies. Half of these targets held strongly anti-Semitic beliefs. The targets’ biographies were created by searching for biographies and testimonials found in various media, and by combining facts and quotes into profiles that were one thousand words in length. Stories were constructed to have parallel structure and elements–for instance, each target story detailed events in childhood that shaped their belief system, and each story described role models that shaped the target’s behavior. Four of the stories involved targets from likable backgrounds, and the other four stories involved targets from dislikable backgrounds. Specifically, the eight biographies were divided up as follows: two never had an association with a neo-Nazi group; two began their lives normally, but then later joined a Neo-Nazi group; two began their lives in Neo-Nazi groups but later chose a life outside these groups; and lastly, two began their lives in Neo-Nazi groups and remained in these groups. Likable and dislikable stories were defined by group membership of the target at the end of the biography (e.g. a target that began their life as a Neo-Nazi, but left the group by the end of the biography was considered likable).</p>
        <p>Participants were instructed to reflect on how they felt about the targets at the end of the biography. After each biography, participants filled out a brief questionnaire regarding how much they liked the target, how much time they would like to spend with the target, and how much they thought the target would like them. Participants were also asked to identify each of the targets and recount details of the target’s story as a way of ensuring that all the targets were equally and accurately remembered. Additionally, prior to scanning, they were shown the action and control video clips performed by the same actors that they would view in the scanner, for familiarization.</p>
        <p>To account for possible sex differences, in each condition (likable targets and dislikable targets) there were two male targets and two female targets for each type of story. Likable targets were characterized as being open-minded, intelligent and positive in nature. By contrast, dislikable targets were strongly racist and anti-Semitic, uninterested in education, cynical of the world and expressly ungrateful for gifts bestowed to them. To accurately assess the likability of each target, in a separate behavioral pilot study, we asked 26 college students from the university subject pool to rate the target stories. Participants in this pilot study labeled the anti-Semitic, dislikable targets as significantly less likable than their counterparts (<italic>t</italic>(25) = −22.744, p&lt;.000001). Additionally, to control for physical appearance of the actors, the pairing of stories and actors was counterbalanced. No significant differences were found between the likable targets (<italic>t</italic>(12) = 2.02, p&gt;.05), or the dislikable targets (<italic>t</italic>(12) = 1.064, p&gt;.05) of different versions.</p>
      </sec>
      <sec id="s2c">
        <title>Stimuli Used in fMRI</title>
        <p>Inside the scanner, participants viewed 2-s movie clips (shown twice, back-to-back) of the target reaching for, grasping, and bringing a water bottle to their lips with the right hand (see <xref ref-type="fig" rid="pone-0046809-g001">Figure 1</xref> for experimental design). Half of the clips displayed likable targets performing the action, and half displayed dislikable people performing the identical action. A 1-s still photo from the first frame of the video clip preceded the action clip in order for the participant to adequately process the target’s identity. As a control condition, clips of the same length, with the 1-s preceding still photo, were shown in which the target sat still with their right hand resting near the water bottle. Targets maintained neutral affect while performing actions. All actors were between 18–30 years of age to match the ages of the targets.</p>
        <fig id="pone-0046809-g001" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0046809.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Schematic illustration of experimental design.</title>
            <p>Each trial began with a one sentence reminder of each target to be viewed in that given trial. A 1-s still photo from the first frame of the video clip preceded the action clip, which was shown twice, back-to-back. The action clips were followed by a question about how much the subject liked the viewed targets on a Likert scale from 1 to 4. The trial ended with a 12-second rest period that consisted of a centered “X” on a blank background screen. Circles used in the manuscript to protect the actor’s identity.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.g001" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2d">
        <title>Task Design and Procedure</title>
        <p>             <list list-type="alpha-lower"><list-item><p><bold>fMRI of Action Observation.</bold> The video clips were presented with MATLAB <xref ref-type="bibr" rid="pone.0046809-Matlab1">[31]</xref>(The Mathworks, Inc., Natrick, MA), using the freely available Psychophysics Toolbox Version 3 software <xref ref-type="bibr" rid="pone.0046809-Brainard1">[32]</xref>. The visual stimuli were projected onto a rear projection screen at the end of the scanner bore which subjects viewed through a mirror mounted on the head coil. Participants were instructed to reflect on their feelings about the target while they viewed the movie clips during scanning.</p></list-item></list>A block design was used where two likable or two unlikable targets were presented together in each block. Trial blocks were preceded by a cue screen that presented two sentences serving as reminders for the participant of which targets they were about to view (e.g., In the case of likable targets: “Stephanie is a musician in New York. Julie wanted to raise her son to have an open mind.”). The cue screen was followed by a fixation cross (jittered 1–2-s), after which the clips were played for 12-s. After the clips were presented, a probe screen (5-s) followed asking the subjects to rate how much they liked the people they just viewed on a scale of 1 to 4, with 4 being “like very much.” The probe screen was followed by a 12-s rest condition. The presentation order of the block conditions was a pseudo-random, counterbalanced order to control for 1-back presentation history <xref ref-type="bibr" rid="pone.0046809-ImmordinoYang1">[30]</xref>. Each functional run consisted of ten blocks total, and there were three total functional runs conducted.</p>
        <list list-type="alpha-lower">
          <list-item>
            <p><bold>Behavioral Measures.</bold> Prior to scanning, participants completed an ethnicity scale <xref ref-type="bibr" rid="pone.0046809-Phinney1">[29]</xref>, a group membership scale based upon Schmitt et al. (2002) <xref ref-type="bibr" rid="pone.0046809-Schmitt1">[33]</xref>, the Interpersonal Reactivity Index (IRI) <xref ref-type="bibr" rid="pone.0046809-Davis1">[34]</xref>, the Brief Mood Introspection Scale (BMIS) <xref ref-type="bibr" rid="pone.0046809-Mayer1">[35]</xref>, as well as likability ratings of all the targets after the completion of each biography. Further information on these scales and correlations between scores on these questionnaires and classification accuracy are reported in the Supporting Materials (<xref ref-type="supplementary-material" rid="pone.0046809.s001">Figure S1</xref> and <xref ref-type="supplementary-material" rid="pone.0046809.s002">Figure S2</xref>). At the conclusion of the scanning session, participants were interviewed and debriefed. Interviews followed a script to identify how the participants felt about the targets when they viewed them in the scanner in addition to how well they remembered the targets. Participants’ responses were recorded during the interview. After the interview, we informed them to the purpose of the study, as well as revealing that the targets were actors.</p>
          </list-item>
        </list>
        <sec id="s2d1">
          <title>Image Acquisition</title>
          <p>Images were acquired with a 3-Tesla Siemens MAGNETON Trio System in the Dornsife Cognitive Neuroscience Imaging Center at the University of Southern California. Three functional runs, one anatomical MPRAGE, and one T2 weighted image was acquired for each subject.</p>
          <p>Structural T<sub>1</sub>-weighted magnetization-prepared rapid gradient echo (MPRAGE) images were acquired (TR = 1,950 ms, TE = 30 ms, 224×256×176 matrix, 154 slices). 154 volumes of echo-planar volumes were acquired continuously with 37 slices per volume, and with the following parameters: TR = 2000 ms, TE = 30 ms, flip angle = 90°, 64×64 matrix with a spatial resolution of 3.5×3.5×3.5 mm, and interslice time = 54 ms, with no slice gap.</p>
        </sec>
      </sec>
      <sec id="s2e">
        <title>Data Analysis</title>
        <list list-type="alpha-lower">
          <list-item>
            <p><bold>Multivariate Pattern Analysis.</bold> Multivariate pattern analysis is a technique that uses machine learning algorithms to discriminate between neural activity patterns that differ between experimental conditions and/or stimuli types <xref ref-type="bibr" rid="pone.0046809-Norman1">[24]</xref>, <xref ref-type="bibr" rid="pone.0046809-Kriegeskorte1">[26]</xref>, <xref ref-type="bibr" rid="pone.0046809-Haynes1">[36]</xref>, <xref ref-type="bibr" rid="pone.0046809-Mur1">[37]</xref>. While univariate fMRI data analysis techniques analyze each voxel’s activity individually, multivariate pattern analysis examines activity across several voxels together, allowing an examination of the spatial distribution of activity in a given region <xref ref-type="bibr" rid="pone.0046809-Norman1">[24]</xref>, <xref ref-type="bibr" rid="pone.0046809-Haynes1">[36]</xref>.</p>
          </list-item>
        </list>
        <p>MVPA was performed using the PyMVPA software package <xref ref-type="bibr" rid="pone.0046809-Hanke1">[38]</xref>, implementing a linear support vector machine from LibSVM (<ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" xlink:type="simple">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</ext-link>). For each subject, data from the 3 functional runs were concatenated and motion corrected to the middle volume of the entire time series using FSL (FMRIB’s Software Library, <ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl/index.html" xlink:type="simple">http://www.fmrib.ox.ac.uk/fsl/index.html</ext-link>) and were then linearly detrended and converted to Z scores by run.</p>
        <p>Given that the design of the experiment was a block design, we focused the MVPA analysis on the data from the entire duration of the 12-s blocks. With a 2-s TR, that provided six brain volumes per condition block for analysis, which were analyzed separately. To account for the delay in the hemodynamic response, we included all volumes from six seconds after the onset of each block to six seconds after the end of each block. Six regions of interest were defined based on regions previously implicated in action observation: bilateral pars opercularis, bilateral pars triangularis, and bilateral inferior parietal lobule (IPL). Pars opercularis and pars triangularis regions of interest were defined using the Harvard-Oxford cortical atlas, which is included with FSL, with a probability threshold of 70%. The left and right IPL were defined separately, using the Juelich cortical atlas, also included with FSL, with probability threshold of 85%. Each region of interest was then warped from standard space into each individual subject’s functional space. In each ROI, we performed 2 different types of classification. We performed a 2-way discrimination between the following conditions: likable individuals performing an action (Action Like) and dislikable individuals performing an action (Action Dislike). In addition, a 2-way discrimination between likable individuals in the control condition (Control Like) and dislikable individuals in the control condition (Control Dislike) was performed. We also performed 2 additional types of exploratory classifications, the results of which are reported in the Supporting Materials. A leave-one-out cross-validation approach was implemented where the classifier was trained on two functional runs and tested on the remaining run for each step of the cross-validation. The outcome of each step is classifier accuracy (performance), which was determined by dividing the number of correct classifier guesses by the number of test trials. Since we had 3 functional runs, cross-validation was repeated three times, and the accuracy results of the classifier for each step were then averaged together. In order to test the statistical significance of the results, a one sample t-test was conducted for each ROI across subjects, using the chance level as the test value, to test whether the sample’s classifier accuracy was significantly above chance.</p>
        <p>In addition to the ROI analysis, we also performed a whole brain spherical searchlight analysis to investigate whether any regions falling just outside our regions of interest would have above chance classifier accuracy <xref ref-type="bibr" rid="pone.0046809-Kriegeskorte2">[27]</xref>, <xref ref-type="bibr" rid="pone.0046809-Haynes1">[36]</xref>. A searchlight radius of 4 voxels (50 voxel clusters) was selected. In this method, multiple multivariate pattern classifications were carried out for a sphere centered on each voxel in the brain. The same linear SVM classifier with a leave-one-out cross validation was used for this analysis producing accuracy maps for each subject. Each subject’s map was warped into the Montreal Neurological Institute (MNI) standard space. In order to test for statistical significance of the resulting searchlight accuracy maps, t-tests were used to compare the 17 subjects’ accuracy maps to chance value (e.g. 0.5 for the Action Like and Action Dislike analysis). The results were then FDR corrected for multiple comparisons, p&lt;0.05.</p>
        <list list-type="alpha-lower">
          <list-item>
            <p><bold>Univariate Analysis.</bold> All fMRI and structural MRI pre-processing were completed using BrainVoyager <xref ref-type="bibr" rid="pone.0046809-Goebel1">[39]</xref>. Anatomical images were normalized to standard space with the following steps: inhomogeneity correction, alignment to ACPC space, and then conformation to Talairach space <xref ref-type="bibr" rid="pone.0046809-Talairach1">[40]</xref>. The fMRI data were first preprocessed for slice scan time correction using cubic spline interpolation in ascending, interleaved order, after which 3D motion correction was performed along six axes. The second run of the session was coregistered manually to the MPRAGE anatomical volume and transformed into Talairach space. After motion correction, the runs were aligned to the second functional run from the session. The data were then smoothed with an 8 mm FWHM 3d Gaussian kernel and temporally filtered using a high-pass filter.</p>
          </list-item>
        </list>
        <p>At the first level of analysis, a general linear model was applied using the canonical hemodynamic response function (HRF). Six explanatory variables were included in the model: prime, likable targets performing an action, disliked targets performing an action, likable target action control, dislikable target action control, and probe. Minor head movements along six axes that took place during the runs were included as regressors of no interest into the design matrix to reduce motion artifacts. At the second level of analysis, the individual runs were included in a random effects (RFX) general linear model (GLM) analysis using both a region of interest (ROI) and a whole brain analysis respectively. To more directly measure activity within areas associated with action observation, regions of interest were hand-drawn and the activity inside was averaged across the runs to provide measures of contrast between conditions. ROIs were hand-drawn for each subject based upon anatomical boundaries detailed in <xref ref-type="bibr" rid="pone.0046809-Damasio1">[41]</xref> (See <xref ref-type="fig" rid="pone-0046809-g002">Figure 2</xref> for locations; see <xref ref-type="supplementary-material" rid="pone.0046809.s005">Table S1</xref> for boundaries). The regions were drawn on each subject’s Talairach-transformed anatomical images using BrainVoyager’s hand drawing tool. Analysis took the form of a random effects analysis of the comparison of the averaged time course of the functional BOLD data contained in the individual ROIs using a p-value of less than.05. Analyses were done using a t-test on the baseline corrected beta value difference between comparisons of pairs of conditions (e.g., Action Dislike vs Action Like). Lastly, results from the searchlight analysis that were located outside the a priori defined regions of interest were used as a mask in a univariate analysis.</p>
        <fig id="pone-0046809-g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0046809.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>A priori defined regions of interest.</title>
            <p>ROIs were drawn on Talairach transformed MPRAGE images by hand using BrainVoyager. Limits were derived using Damasio (2005) for all regions. Pars triangularis (IFG; p.t.; shown in red), pars opercularis (IFG, p.o.; shown in blue), and inferior parietal lobule (IPL; shown in green).</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.g002" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
        <title>(a) Behavioral</title>
        <p>Participants rated the dislikable (neo-Nazi) targets as significantly less likable than the likable targets (controls) (<italic>t</italic> (16) = −19.755, p&lt;0.0001). In the pre-scan training session, participants rated the neo-Nazi targets less likable, as well as less apt to like, and less likely to spend time with the subject himself. Immediately following each block during the scanning session, participants were also asked to rate how much they liked the people performing the actions on a scale of 1–4, with 1 being you don’t like them at all, and 4 being you like them a lot. These ratings indicated that dislikable (neo-Nazi) targets were rated as significantly less likable by participants as compared to the likable targets (p&lt;0.000001).</p>
      </sec>
      <sec id="s3b">
        <title>(b) Multivariate Pattern Analysis (MVPA)</title>
        <p>The two-way discrimination between Action Like and Action Dislike did not produce statistically significant results in any of the ROIs, nor did the two-way discrimination between Control Like and Control Dislike (see <xref ref-type="table" rid="pone-0046809-t001">Table 1</xref>).</p>
        <table-wrap id="pone-0046809-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0046809.t001</object-id><label>Table 1</label><caption>
            <title>Region of Interest Classification Accuracies.</title>
          </caption><alternatives>
            <graphic id="pone-0046809-t001-1" mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.t001" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" colspan="1" rowspan="1">
                    <italic>Discrimination</italic>
                    <italic>Conditions</italic>
                  </td>
                  <td align="left" colspan="1" rowspan="1">
                    <italic>ROI</italic>
                  </td>
                  <td align="left" colspan="1" rowspan="1">
                    <italic>Chance Level</italic>
                  </td>
                  <td align="left" colspan="1" rowspan="1">
                    <italic>% Accuracy</italic>
                  </td>
                  <td align="left" colspan="1" rowspan="1">
                    <italic>p-value</italic>
                  </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Action Like,Action Dislike</td>
                  <td align="left" colspan="1" rowspan="1">IFG, p.o., left</td>
                  <td align="left" colspan="1" rowspan="1">50%</td>
                  <td align="left" colspan="1" rowspan="1">50%</td>
                  <td align="left" colspan="1" rowspan="1">.870</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IFG, p.o, right</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">50%</td>
                  <td align="left" colspan="1" rowspan="1">.916</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IFG, p.t., left</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">49%</td>
                  <td align="left" colspan="1" rowspan="1">.861</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IFG, p.t., right</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">54%</td>
                  <td align="left" colspan="1" rowspan="1">.150</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IPL, left</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">49%</td>
                  <td align="left" colspan="1" rowspan="1">.578</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IPL, right</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">48%</td>
                  <td align="left" colspan="1" rowspan="1">.234</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Control Like,Control Dislike</td>
                  <td align="left" colspan="1" rowspan="1">IFG, p.o., left</td>
                  <td align="left" colspan="1" rowspan="1">50%</td>
                  <td align="left" colspan="1" rowspan="1">52%</td>
                  <td align="left" colspan="1" rowspan="1">.447</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IFG, p.o, right</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">51%</td>
                  <td align="left" colspan="1" rowspan="1">.506</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IFG, p.t., left</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">53%</td>
                  <td align="left" colspan="1" rowspan="1">.213</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IFG, p.t., right</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">54%</td>
                  <td align="left" colspan="1" rowspan="1">.209</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IPL, left</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">50%</td>
                  <td align="left" colspan="1" rowspan="1">.819</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">IPL, right</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">50%</td>
                  <td align="left" colspan="1" rowspan="1">.981</td>
                </tr>
              </tbody>
            </table>
          </alternatives><table-wrap-foot>
            <fn id="nt101">
              <p><italic>Note.</italic> IFG, p.o. = Inferior Frontal Gyrus, pars opercularis; IFG, p.t. = inferior frontal gyrus, pars triangularis; IPL = inferior parietal lobule. * indicates statistical significance, p&lt;0.05.</p>
            </fn>
          </table-wrap-foot></table-wrap>
        <p>The same discriminations were performed in a whole brain searchlight analysis. The two-way discrimination between Action Like and Action Dislike revealed a significant classifier accuracy cluster in the right vPMC (<italic>p</italic>&lt;.05, FDR corrected for multiple comparisons) just outside of the right pars opercularis ROI (See <xref ref-type="fig" rid="pone-0046809-g004">Figure 4</xref>). Classification accuracy in this region was above chance level for all participants, with the average of the peak classification accuracy across subjects being 58.47% (<xref ref-type="fig" rid="pone-0046809-g003">Figure 3</xref> for significant cluster location, see <xref ref-type="fig" rid="pone-0046809-g004">Figure 4</xref> for classification accuracy per subject). The two-way discrimination between Control Like and Control Dislike did not reveal any significant clusters in motor-related regions.</p>
        <fig id="pone-0046809-g003" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0046809.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Searchlight analysis results.</title>
            <p>Classification accuracy in the right vPMC across subjects that survived FDR correction for multiple comparisons (FDR, p&lt;.05) is displayed. Peak voxel coordinate in MNI space is (15, 64, 46).</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.g003" xlink:type="simple"/>
        </fig>
        <fig id="pone-0046809-g004" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0046809.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Searchlight classifier performance within right vPMC for individual subjects.</title>
            <p>Each bar represents searchlight peak classifier performance within the right vPMC in an individual subject for the Action-Like and Action-Dislike discrimination analysis. Chance performance is 0.5.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.g004" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3c">
        <title>(c) Univariate Analysis</title>
        <p>For the comparison between all action conditions (Likable and Dislikable) and rest, all action observation ROIs were significantly more active for action conditions than for the rest conditions: left and right IFG, pars opercularis, left and right IFG, pars triangularis, and left and right IPL (see <xref ref-type="fig" rid="pone-0046809-g005">Figure 5</xref>; see Supporting Materials for whole-brain analysis). There were no significant differences for any other comparisons within the ROIs. Lastly, when the vPMC significant cluster from the searchlight analysis was used as an ROI, no significant differences were found for the comparison between Action Like and Action Dislike.</p>
        <fig id="pone-0046809-g005" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0046809.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Region of Interest univariate analysis results.</title>
            <p>Differences in activation while watching all action clips compared with rest condition (Action Observation &gt; Rest) are displayed. The <italic>a priori</italic> defined ROIs (IFG, pars triangularis; IFG, pars opercularis; IPL) were used as pre-threshold masks in the analysis. Results are displayed at p&lt;0.01 (FDR corrected).</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.g005" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>We set out to investigate whether motor-related regions involved in action observation are modulated by a social factor, interpersonal liking derived from social group membership. Based on previous research that indicates these regions are affected by socially relevant factors, we predicted that they would have differential neural signatures during the viewing of a likable person performing an action as opposed to a dislikable person performing the same action. The whole-brain searchlight classifier found above-chance classification in the right vPMC discriminating between watching a person you like perform an action and watching a person you dislike perform an action, in line with our predictions. Additionally, these results were specific to action observation, as the classification of the control conditions of like and dislike demonstrated no significant difference. By contrast, the a priori regions of interest did not display differences in level of neural activity, as measured with univariate methods. Further, when this significant searchlight classifier cluster was used to mask the comparison of Action Like and Action Dislike in a univariate analysis, no significant differences were found. We believe this suggests that the classifier was able to extract a difference in activation patterns where the univariate analysis failed to detect an effect.</p>
      <p>Our results are novel in that they demonstrate for the first time these motor-related regions are modulated during action observation by interpersonal liking derived from social group membership, a higher level classification which is not based on visual cues of group membership. Neuroimaging studies that have shown differential neural activity for group membership have typically used race as the defining factor for groups <xref ref-type="bibr" rid="pone.0046809-Cunningham1">[23]</xref>, <xref ref-type="bibr" rid="pone.0046809-Phelps1">[42]</xref>. Additionally, previous studies of action observation have indicated differential corticospinal excitability and differential BOLD activity levels in motor-related neural regions for perceived differences in social group membership, although these studies have also relied on visual cues of physical differences to indicate social group membership status (i.e. race). These past results are not surprising, given the body of literature that suggests differential activity in these action observation-related neural regions for self-other distinction <xref ref-type="bibr" rid="pone.0046809-Uddin1">[14]</xref>, <xref ref-type="bibr" rid="pone.0046809-Uddin2">[43]</xref>, as well as for individuals who are physically dissimilar from the self <xref ref-type="bibr" rid="pone.0046809-Liew2">[9]</xref>. In our study, the likable targets, dislikable targets, and participants themselves were physically similar to each other to rule out effects of physical cues to group membership. Here, we begin to tease apart this complex relationship by taking advantage of two social groups that appear physically similar, but consider each other as dislikable outgroups. Similar to our findings, a more abstract definition of group membership (i.e. political party affiliation) was found to have an effect on the perception of touch <xref ref-type="bibr" rid="pone.0046809-Serino1">[44]</xref>. Together, these results indicate that it may indeed be the higher level abstraction of group membership, and not only differences in physical appearance, that affect basic sensory-motor processing.</p>
      <p>Additionally, unlike previous studies, we address the more basic question of whether these socially relevant factors influence the perception of simple object directed actions, rather than higher level action understanding through communicative cultural gestures. Previous studies comparing the observation of actors of different races performing culture-specific gestures have shown differential corticospinal excitability and neural activity <xref ref-type="bibr" rid="pone.0046809-MolnarSzakacs1">[5]</xref>, <xref ref-type="bibr" rid="pone.0046809-Liew1">[6]</xref>. While these studies are important in proving that social and cultural factors can influence motor representations of communicative and meaningful hand gestures, it is of interest to investigate whether these social factors solely influence neural processing for communicative gestures with cultural meaning, or whether their influence extends to non-cultural, object directed actions, as well. Our finding that the ventral premotor region in the right hemisphere displayed differential neural activity for the observation of simple object directed motor actions appears to support this latter notion.</p>
      <p>In this study, the neural pattern of activity in the vPMC was modulated by interpersonal liking derived from social group membership. The right hemisphere has been suggested to be the hemisphere that plays a larger role in social and emotional processing in humans <xref ref-type="bibr" rid="pone.0046809-Ley1">[45]</xref>–<xref ref-type="bibr" rid="pone.0046809-DeKosky1">[47]</xref>. Although our visual stimuli were simple object-directed actions, the biographies of the targets were emotionally charged indicators of which social group the target belonged. The subjects were instructed to remember how they felt about the targets while viewing the video clips in the scanner, and they did, in fact, report feeling differently about how much they liked the different groups of targets. This demonstrates that the amount of interpersonal liking was modulated by group membership, and that this higher level processing may color the observation of actions, particularly in the right vPMC.</p>
      <p>Overall, these results contribute to the longstanding evidence supporting the notion that perception of ingroup and outgroup members implicitly biases information processing in fundamental neural networks. Behaviorally, actions from outgroup members can be perceived and described as more negatively <xref ref-type="bibr" rid="pone.0046809-Maass1">[48]</xref>, <xref ref-type="bibr" rid="pone.0046809-Gaertner1">[49]</xref>, or judged as more slow <xref ref-type="bibr" rid="pone.0046809-Molenberghs1">[50]</xref>, as opposed to ingroup members’ actions, implying that differential perception and processing of ingroup members and outgroup members may occur. Supporting behavioral findings, physiological and neural differences have also been found when perceiving ingroup and outgroup members <xref ref-type="bibr" rid="pone.0046809-Brown1">[11]</xref>, <xref ref-type="bibr" rid="pone.0046809-Cunningham1">[23]</xref>. This study expands our knowledge of this phenomenon by indicating that these higher level cognitive constructs can affect perception, and specifically, can modulate sensory-motor processing.</p>
      <p>It remains to be seen whether these differences in neural patterns of activity will persist during an action observation task when the disliked outgroup is physically similar to oneself, but it is not socially acceptable to express disdain for members of the social group. The main focus of this study was specifically to examine interpersonal liking as it is derived from social group membership, in a circumstance that is free from social stigma against disliking the outgroup member. An additional concern is social desirability, or the desire of the participant to give a response they believe the researchers want to hear. Although it is difficult to rule this out in the current study, it is worth noting that the subjects had quite visible negative reactions to the emotionally evocative stories, possibly suggesting that their feelings towards the targets corresponded to their negative ratings. Investigating the difference between likability for an individual who is disliked for a personal reason versus for a social reason is an interesting topic for a future study.</p>
      <p>Our results indicate that socially relevant factors, such as interpersonal liking and group membership, can affect motor-related neural regions, those underlying action observation. Specifically, the right vPMC exhibits differential neural activity patterns during the observation of a likable person, as opposed to a dislikable person specifically during action observation. Our research confirms previous findings that activity in action observation related neural regions can be modulated by social group membership, and we extend this finding by removing any possible effects of physical differences between group members and expanding beyond communicative cultural gestures. Our data suggest that neural regions involved in action observation of simple goal-oriented actions are tuned to interpersonal liking derived from social group membership.</p>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pone.0046809.s001" mimetype="image/tiff" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.s001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p><bold>Individual subject searchlight accuracy maps for Action Like-Action Dislike classification.</bold> Crosshair is located in the vPMC cluster that was significant at the group level. All individual subject maps are warped into MNI space, and thresholded so that only regions showing above chance classification (greater than 50%) are shown.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0046809.s002" mimetype="image/tiff" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.s002" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p><bold>Whole-brain univariate analysis for all action versus rest.</bold> Differences in whole-brain activation while watching all action clips compared with rest condition (Action Observation &gt; Rest) are displayed. Results are displayed at p&lt;0.05 (FDR corrected).</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0046809.s003" mimetype="image/tiff" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.s003" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p><bold>Relationship between ethnicity scores and searchlight peak accuracy values from vPMC.</bold> Correlation conducted across subjects, r = .46, p&gt;.05, n = 15.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0046809.s004" mimetype="image/tiff" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.s004" xlink:type="simple">
        <label>Figure S4</label>
        <caption>
          <p><bold>Relationship between ethnicity scores and peak accuracy values for the right IPL.</bold> Correlation conducted across subjects during the 4-class discrimination, r = .55, p&lt;.05, n = 15.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0046809.s005" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.s005" xlink:type="simple">
        <label>Table S1</label>
        <caption>
          <p>
            <italic>Region of Interest Classification Accuracies.</italic>
          </p>
          <p>(DOCX)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pone.0046809.s006" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pone.0046809.s006" xlink:type="simple">
        <label>Table S2</label>
        <caption>
          <p>
            <italic>Hand Drawn ROI Limits.</italic>
          </p>
          <p>(DOCX)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We would like to thank Sook-Lei Liew, Kathleen Garrison, Henryk Bukowski, David Herman, and Tong Sheng for their assistance with this study and manuscript.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pone.0046809-Rizzolatti1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rizzolatti</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Craighero</surname><given-names>L</given-names></name> (<year>2004</year>) <article-title>The mirror-neuron system</article-title>. <source>Annu Rev Neurosci</source> <volume>27</volume>: <fpage>169</fpage>–<lpage>192</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Rizzolatti2">
        <label>2</label>
        <mixed-citation publication-type="other" xlink:type="simple">Rizzolatti G, Fadiga L (1998) Grasping objects and grasping action meanings: the dual role of monkey rostroventral premotor cortex (area F5). Novartis Found Symp 218: 81–95; discussion 95–103.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Gallese1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gallese</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Keysers</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rizzolatti</surname><given-names>G</given-names></name> (<year>2004</year>) <article-title>A unifying view of the basis of social cognition</article-title>. <source>Trends Cogn Sci</source> <volume>8</volume>: <fpage>396</fpage>–<lpage>403</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Grafton1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grafton</surname><given-names>ST</given-names></name>, <name name-style="western"><surname>Arbib</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Fadiga</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Rizzolatti</surname><given-names>G</given-names></name> (<year>1996</year>) <article-title>Localization of grasp representations in humans by positron emission tomography. 2. Observation compared with imagination</article-title>. <source>Exp Brain Res</source> <volume>112</volume>: <fpage>103</fpage>–<lpage>111</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-MolnarSzakacs1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Robles</surname><given-names>FJ</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Do you see what I mean? Corticospinal excitability during observation of culture-specific gestures</article-title>. <source>PLoS One</source> <volume>2</volume>: <fpage>e626</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Liew1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liew</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Han</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Aziz-Zadeh</surname><given-names>L</given-names></name> (<year>2011</year>) <article-title>Familiarity modulates mirror neuron and mentalizing regions during intention understanding</article-title>. <source>Hum Brain Mapp</source> <volume>32</volume>: <fpage>1986</fpage>–<lpage>1997</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Buccino1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buccino</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lui</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Canessa</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Patteri</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Lagravinese</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Neural circuits involved in the recognition of actions performed by nonconspecifics: an FMRI study</article-title>. <source>J Cogn Neurosci</source> <volume>16</volume>: <fpage>114</fpage>–<lpage>126</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Dsy1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Désy</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Théoret</surname><given-names>H</given-names></name> (<year>2007</year>) <article-title>Modulation of motor cortex excitability by physical similarity with an observed hand action</article-title>. <source>PLoS One</source> <volume>2</volume>: <fpage>e971</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Liew2">
        <label>9</label>
        <mixed-citation publication-type="other" xlink:type="simple">Liew S-L, Sheng T, Aziz-Zadeh L (Submitted) Experience with a congenital amputee modulates one’s own sensorimotor regions during action observation.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Weisbuch1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weisbuch</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ambady</surname><given-names>N</given-names></name> (<year>2008</year>) <article-title>Affective divergence: automatic responses to others’ emotions depend on group membership</article-title>. <source>J Pers Soc Psychol</source> <volume>95</volume>: <fpage>1063</fpage>–<lpage>1079</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Brown1">
        <label>11</label>
        <mixed-citation publication-type="other" xlink:type="simple">Brown L, Bradley MM, Lang PJ (2006) Affective reactions to pictures of ingroup and outgroup members. Biol Psychol. 303–311.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Hart1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hart</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Whalen</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Shin</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>McInerney</surname><given-names>SC</given-names></name>, <name name-style="western"><surname>Fischer</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>Differential response in the human amygdala to racial outgroup vs ingroup face stimuli</article-title>. <source>Neuroreport</source> <volume>11</volume>: <fpage>2351</fpage>–<lpage>2355</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Xu1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Xu</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Zuo</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Han</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Do you feel my pain? Racial group membership modulates empathic neural responses</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>8525</fpage>–<lpage>8529</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Uddin1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uddin</surname><given-names>LQ</given-names></name>, <name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Zaidel</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>rTMS to the right inferior parietal lobule disrupts self-other discrimination</article-title>. <source>Soc Cogn Affect Neurosci</source> <volume>1</volume>: <fpage>65</fpage>–<lpage>71</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Kaplan1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaplan</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Aziz-Zadeh</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Uddin</surname><given-names>LQ</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>The self across the senses: an fMRI study of self-face and self-voice recognition</article-title>. <source>Soc Cogn Affect Neurosci</source> <volume>3</volume>: <fpage>218</fpage>–<lpage>223</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Turner1">
        <label>16</label>
        <mixed-citation publication-type="other" xlink:type="simple">Turner JC, Hogg MA, Oakes PJ, Reicher SD, Wetherell MS (1987) Rediscovering the social group: A self-categorization theory. Cambridge, MA: Basil Blackwell.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Hornstein1">
        <label>17</label>
        <mixed-citation publication-type="other" xlink:type="simple">Hornstein H (1976) Cruelty and kindness: A new look at aggression and altruism. Englewood Cliffs, NJ: Prentice-Hall.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Kaplan2">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaplan</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Getting a grip on other minds: mirror neurons, intention understanding, and cognitive empathy</article-title>. <source>Soc Neurosci</source> <volume>1</volume>: <fpage>175</fpage>–<lpage>183</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Gazzola1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gazzola</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Aziz-Zadeh</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Keysers</surname><given-names>C</given-names></name> (<year>2006</year>) <article-title>Empathy and the somatotopic auditory mirror system in humans</article-title>. <source>Curr Biol</source> <volume>16</volume>: <fpage>1824</fpage>–<lpage>1829</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Losin1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Losin</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Cross</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Dapretto</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Race modulates neural activity during imitation</article-title>. <source>Neuroimage</source> <volume>59</volume>: <fpage>3594</fpage>–<lpage>3603</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Hein1">
        <label>21</label>
        <mixed-citation publication-type="other" xlink:type="simple">Hein G, Silani G, Preuschoff K, Batson CD, Singer T (2010) Neural Responses to Ingroup and Outgroup Members’ Suffering Predict Individual Differences in Costly Helping. Neuron. 149–160.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Hewstone1">
        <label>22</label>
        <mixed-citation publication-type="other" xlink:type="simple">Hewstone M, Rubin M, Willis H (2002) Intergroup Bias. Annu. Rev. Psychol. 575–604.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Cunningham1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cunningham</surname><given-names>WA</given-names></name>, <name name-style="western"><surname>Raye</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>MK</given-names></name> (<year>2004</year>) <article-title>Implicit and explicit evaluation: FMRI correlates of valence, emotional intensity, and control in the processing of attitudes</article-title>. <source>J Cogn Neurosci</source> <volume>16</volume>: <fpage>1717</fpage>–<lpage>1729</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Norman1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Polyn</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Detre</surname><given-names>GJ</given-names></name>, <name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name> (<year>2006</year>) <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source>Trends Cogn Sci</source> <volume>10</volume>: <fpage>424</fpage>–<lpage>430</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Pereira1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pereira</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Mitchell</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Botvinick</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Machine learning classifiers and fMRI: a tutorial overview</article-title>. <source>Neuroimage</source> <volume>45</volume>: <fpage>S199</fpage>–<lpage>209</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Kriegeskorte1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Bandettini</surname><given-names>P</given-names></name> (<year>2007</year>) <article-title>Analyzing for information, not activation, to exploit high-resolution fMRI</article-title>. <source>Neuroimage</source> <volume>38</volume>: <fpage>649</fpage>–<lpage>662</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Kriegeskorte2">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bandettini</surname><given-names>P</given-names></name> (<year>2006</year>) <article-title>Information-based functional brain mapping</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>103</volume>: <fpage>3863</fpage>–<lpage>3868</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Singer1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singer</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name>, <name name-style="western"><surname>O’Doherty</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name>, <name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Empathic neural responses are modulated by the perceived fairness of others</article-title>. <source>Nature</source> <volume>439</volume>: <fpage>466</fpage>–<lpage>469</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Phinney1">
        <label>29</label>
        <mixed-citation publication-type="other" xlink:type="simple">Phinney JS (1992) The multigroup ethnic identity measure. Journal of Adolescent Research. 156.</mixed-citation>
      </ref>
      <ref id="pone.0046809-ImmordinoYang1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Immordino-Yang</surname><given-names>MH</given-names></name>, <name name-style="western"><surname>McColl</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Damasio</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Damasio</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Neural correlates of admiration and compassion</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>: <fpage>8021</fpage>–<lpage>8026</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Matlab1">
        <label>31</label>
        <mixed-citation publication-type="other" xlink:type="simple">Matlab version 2007a N (2007). Massachusetts: The Mathworks Inc.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Brainard1">
        <label>32</label>
        <mixed-citation publication-type="other" xlink:type="simple">Brainard D (1997) The Psychophysics Toolbox. Spatial Vision. 433–436.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Schmitt1">
        <label>33</label>
        <mixed-citation publication-type="other" xlink:type="simple">Schmitt MT, Branscombe NR, Kobrynowiz D, Owen S (2002) Perceiving discrimination against one’s gender group has different implications for well-being in women and men.: Personality and Social Psychology Bulletin. 197–210.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Davis1">
        <label>34</label>
        <mixed-citation publication-type="other" xlink:type="simple">Davis M (1983) Measuring individual differences in empathy: Evidence for a multidimensional approach. ournal of Personality and Social Psychology. 113–126.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Mayer1">
        <label>35</label>
        <mixed-citation publication-type="other" xlink:type="simple">Mayer JD, Yvonne NG (1988) The experience and meta-experience of mood.: Journal of Personality and Social Psychology. 102–111.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Haynes1">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haynes</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Decoding mental states from brain activity in humans</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>: <fpage>523</fpage>–<lpage>534</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Mur1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mur</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bandettini</surname><given-names>PA</given-names></name>, <name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name> (<year>2009</year>) <article-title>Revealing representational content with pattern-information fMRI–an introductory guide</article-title>. <source>Soc Cogn Affect Neurosci</source> <volume>4</volume>: <fpage>101</fpage>–<lpage>109</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Hanke1">
        <label>38</label>
        <mixed-citation publication-type="other" xlink:type="simple">Hanke M, Halchenko YO, Sederberg PB, Hanson SJ, Haxby JV, <etal>et al</etal>.. (2009) PyMVPA: A Python toolbox for multivariate pattern analysis of fMRI data.: Neuroinformatics. 37–53.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Goebel1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Esposito</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name> (<year>2006</year>) <article-title>Analysis of functional image analysis contest (FIAC) data with brainvoyager QX: From single-subject to cortically aligned group general linear model analysis and self-organizing group independent component analysis</article-title>. <source>Hum Brain Mapp</source> <volume>27</volume>: <fpage>392</fpage>–<lpage>401</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Talairach1">
        <label>40</label>
        <mixed-citation publication-type="other" xlink:type="simple">Talairach J, Tournoux P (1988) Co-Planar Stereotaxic Atlas of the Human Brain. Thieme Medical Publishers. 122.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Damasio1">
        <label>41</label>
        <mixed-citation publication-type="other" xlink:type="simple">Damasio H (2005) Human Brain Anatomy in Computerized Images. New York: Oxford University Press.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Phelps1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Phelps</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>O’Connor</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Cunningham</surname><given-names>WA</given-names></name>, <name name-style="western"><surname>Funayama</surname><given-names>ES</given-names></name>, <name name-style="western"><surname>Gatenby</surname><given-names>JC</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>Performance on indirect measures of race evaluation predicts amygdala activation</article-title>. <source>J Cogn Neurosci</source> <volume>12</volume>: <fpage>729</fpage>–<lpage>738</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Uddin2">
        <label>43</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Uddin</surname><given-names>LQ</given-names></name>, <name name-style="western"><surname>Kaplan</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Molnar-Szakacs</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Zaidel</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>Self-face recognition activates a frontoparietal “mirror” network in the right hemisphere: an event-related fMRI study</article-title>. <source>Neuroimage</source> <volume>25</volume>: <fpage>926</fpage>–<lpage>935</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Serino1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Serino</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Giovagnoli</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Làdavas</surname><given-names>E</given-names></name> (<year>2009</year>) <article-title>I feel what you feel if you are similar to me</article-title>. <source>PLoS One</source> <volume>4</volume>: <fpage>e4930</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Ley1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ley</surname><given-names>RG</given-names></name>, <name name-style="western"><surname>Bryden</surname><given-names>MP</given-names></name> (<year>1979</year>) <article-title>Hemispheric differences in processing emotions and faces</article-title>. <source>Brain Lang</source> <volume>7</volume>: <fpage>127</fpage>–<lpage>138</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Silberman1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silberman</surname><given-names>EK</given-names></name>, <name name-style="western"><surname>Weingartner</surname><given-names>H</given-names></name> (<year>1986</year>) <article-title>Hemispheric lateralization of functions related to emotion</article-title>. <source>Brain Cogn</source> <volume>5</volume>: <fpage>322</fpage>–<lpage>353</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-DeKosky1">
        <label>47</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DeKosky</surname><given-names>ST</given-names></name>, <name name-style="western"><surname>Heilman</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Bowers</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Valenstein</surname><given-names>E</given-names></name> (<year>1980</year>) <article-title>Recognition and discrimination of emotional faces and pictures</article-title>. <source>Brain Lang</source> <volume>9</volume>: <fpage>206</fpage>–<lpage>214</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Maass1">
        <label>48</label>
        <mixed-citation publication-type="other" xlink:type="simple">Maass A, Salvi D, Arcuri L, Semin GR (1989) Language use in the context of congruent and incongruent ingroup behaviors. Journal of Personality and Social Psychology. 981–993.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Gaertner1">
        <label>49</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gaertner</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Dovidio</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Rust</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Nier</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Banker</surname><given-names>BS</given-names></name>, <etal>et al</etal>. (<year>1999</year>) <article-title>Reducing intergroup bias: elements of intergroup cooperation</article-title>. <source>J Pers Soc Psychol</source> <volume>76</volume>: <fpage>388</fpage>–<lpage>402</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0046809-Molenberghs1">
        <label>50</label>
        <mixed-citation publication-type="other" xlink:type="simple">Molenberghs P, Halász V, Mattingley JB, Vanman EJ, Cunnington R (2012) Seeing is believing: Neural mechanisms of action-perception are biased by team membership. Hum Brain Mapp.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>