{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71534d26",
   "metadata": {},
   "source": [
    "# Final Project Summary\n",
    "## Module #5 (Unsupervised Learning & Natural Language Processing)\n",
    "## Mark Streer (DS/ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553581cb",
   "metadata": {},
   "source": [
    "### Abstract:\n",
    "\n",
    "Globally, scientific literature is disseminated in English, yet the language is spoken by fewer than 20% of the world's population, and only 5% speak it natively. Researchers working in non-Anglophone countries normally enlist help from translators and/or editors in order to publish in their second language; however, language professionals are inconsistent in their diction and writing style, leaving their customers to question the value of their services. Could English biomedical corpora be used as reference repositories of expected genre-specific language for translators to consult when translating, and for ESL authors to check/edit their work? In this project, I examined a collection of English technical translations from Japanese by the same translator (myself), finding the topics modeled to correspond to different domains of medicine and healthcare, and to be well differentiated by clustering algorithms as well. Further work will apply the same pipeline to the Japanese source texts, to see how the topics/clusters compare and diverge across these two languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453cc35",
   "metadata": {},
   "source": [
    "### Design:\n",
    "\n",
    "The dataset analyzed consists of the English texts of my technical translations from Japanese to English in 2020-2021. These documents are generally original research articles (RAs) or abstracts in IMRAD format (n=110). The Japanese authors range from graduate students writing their first scientific paper, to professors and physicians writing their 20th; the sophistication of the lexis and syntax in their source texts is similarly diverse. Likewise, scientific corpora are normally drawn from a wide variety of sources and authors. Despite this variation, the rules applied to distill technical Japanese from diverse authors and domains should be relatively **consistent** within any given translator, corresponding to their personal translation style.\n",
    "\n",
    "Preprocessing was applied to remove punctuation and small words (<4 characters); the results were lemmatized using WordNetLemmatizer. Specific other considerations applied in preprocessing and model selection included:\n",
    "* Given the size of the documents (~500-10,000 words), latent Dirichlet allocation (LDA) was expected to perform the best at differentiating topics. However, non-negative matrix factorization (NMF) ultimately generated topics and topic-word loadings that were more interpretable.\n",
    "\n",
    "* Since technical terminology and jargon were expected to play key roles in differentiating topics/domains in a corpus of technical documents, the 1000 most-common English words were added to the stopwords list for vectorization.\n",
    "* For the same reason, a TF-IDF vectorizer was preferred to a simple count vectorizer, to emphasize rare terms which were likely jargon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec59bf",
   "metadata": {},
   "source": [
    "### Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45ff52",
   "metadata": {},
   "source": [
    "#### NMF Topic Model (n=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64447f",
   "metadata": {},
   "source": [
    "![](images/NMF16_topics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e010f4",
   "metadata": {},
   "source": [
    "My personal familiarity with the documents in the corpus leads me to believe that 16 topics is not an unreasonable number. The documents come from a wide variety of customers, from different universities and domains of expertise; one would expect a random selection of documents from PubMed or ScienceDirect to be diverse as well. \n",
    "\n",
    "Several of these topics persisted in an 8-topic model run for comparison (i.e. surgery, COVID-19, cancer, neuroscience, and rehabilitation). Even the newly created categories were similarly interpretable as the coalescing of numerous minor categories. Notable examples include:\n",
    "* **Nursing**: Community health, nursing education, stroke\n",
    "* **Biomolecular Therapeutics**: Stem cell therapeutics, clinical trials (i.e. pharmaceuticals)\n",
    "* **Functional Health**: Community health, social welfare, physiology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f47e5b",
   "metadata": {},
   "source": [
    "#### NMF Topic Model (n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117eae3",
   "metadata": {},
   "source": [
    "![](images/NMF08_topics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136a9ea",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1540a356",
   "metadata": {},
   "source": [
    "K-means clustering (k=16) was applied to the doc-topic matrix resulting from the 16-topic NMF model. For each cluster generated, the doc-topic vectors of each doc in the group were averaged, and individual docs compared with the cluster centroid. Surprisingly, despite the small corpus size, clusters were populated with relevant documents. One finding of particular note is that the mean doc-topic vector usually had one dominant topic, with the next largest in distant second. This held true even for 'smaller' topics in the model (9-16) such as '13.Stroke' and '10.ObGyn', as shown below, supporting the original decision to set n=16 topics in my mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc28d7",
   "metadata": {},
   "source": [
    "![](images/clusterex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce77eb7",
   "metadata": {},
   "source": [
    "![](images/clusterex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fa414",
   "metadata": {},
   "source": [
    "![](images/clusterex3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11beb44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
